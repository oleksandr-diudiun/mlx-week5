{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (15.0.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.4)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.24.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "! pip install pyarrow matplotlib sentencepiece pandas\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import TransformerDecoder, TransformerDecoderLayer\n",
    "import sentencepiece as spm\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "if torch.backends.mps.is_available():  # Check for Apple Silicon GPU availability (requires PyTorch 1.12 or later)\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():  # Check for NVIDIA GPU availability\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Fall back to CPU\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from both Parquet files\n",
    "train_0 = pd.read_parquet('../train/0000.parquet')\n",
    "train_1 = pd.read_parquet('../train/0001.parquet')\n",
    "train_2 = pd.read_parquet('../train/0002.parquet')\n",
    "train_3 = pd.read_parquet('../train/0003.parquet')\n",
    "\n",
    "# Concatenate the two DataFrames into one\n",
    "train = pd.concat([train_0, train_1, train_2, train_3], ignore_index=True)\n",
    "# train['text'] = train['text'].str.slice(start=0, stop=1500)\n",
    "\n",
    "# Filter out elements with less than 2000 characters\n",
    "# train = train[train['text'].str.len() >= 1500]\n",
    "# Reset the index of the filtered DataFrame and drop the old index\n",
    "# Select only the first 10000 rows\n",
    "train = train.iloc[:10000]\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "print(train.shape)\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load('spm_05_text_model.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoryDataset(Dataset):\n",
    "    def __init__(self, stories,  sp, input_tokens_amount, device):\n",
    "        super().__init__()\n",
    "        self.stories = stories\n",
    "        self.sp = sp\n",
    "        self.input_tokens_amount = input_tokens_amount\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stories)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # encoded_story = [sp.PieceToId('<s>')] + self.sp.EncodeAsIds(self.stories[idx])[:(self.input_tokens_amount-1)]\n",
    "        # encoded_target = self.sp.EncodeAsIds(self.stories[idx])[:(self.input_tokens_amount-1)] + [sp.PieceToId('</s>')]\n",
    "        encoded_story = [sp.PieceToId('<s>')] + self.sp.EncodeAsIds(self.stories[idx])\n",
    "        encoded_target = self.sp.EncodeAsIds(self.stories[idx]) + [sp.PieceToId('</s>')]\n",
    "        return torch.tensor(encoded_story, dtype=torch.long, device = self.device), torch.tensor(encoded_target, dtype=torch.long, device = self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, embed_size, head_size, dropout, device):\n",
    "        super().__init__()\n",
    "        self.head_size      = head_size\n",
    "        self.embed_size     = embed_size\n",
    "        self.device         = device\n",
    "        \n",
    "        self.Key   = nn.Linear(self.embed_size, self.head_size, bias=False, device = self.device) # Size: [embed_size x head_size]\n",
    "        self.Query = nn.Linear(self.embed_size, self.head_size, bias=False, device = self.device) # Size: [embed_size x head_size] \n",
    "        self.Value = nn.Linear(self.embed_size, self.head_size, bias=False, device = self.device) # Size: [embed_size x head_size] \n",
    "        \n",
    "        self.Dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask = None):\n",
    "        batchSize, tokens, head_size = x.shape\n",
    "\n",
    "        key   = self.Key(x)    # Size: [batchSize x tokens x head_size]\n",
    "        query = self.Query(x)  # Size: [batchSize x tokens x head_size]\n",
    "        value = self.Value(x)  # Size: [batchSize x tokens x head_size]\n",
    "\n",
    "        tril = torch.tril(torch.ones(tokens, tokens, device = self.device))                 # Size: [tokens_amount x tokens_amount]. Diagonale ones left side only.                                                                      \n",
    "\n",
    "        # Compute Attention scores (\"Affinities\")\n",
    "        attention = query @ key.transpose(-2, -1) * head_size**0.5                          # [Batch Size x Tokens amount x head_size] @ [Batch Size x head_size x Tokens amount] --> [Batch Size x Tokens amount x Tokens amount]\n",
    "       \n",
    "        if mask is not None:\n",
    "            # print(\"mask:\" , mask.shape)\n",
    "            attention = attention.masked_fill(mask == 0, float(-1e9))                     # Size: [batchSize x tokens x tokens]\n",
    "            # print(\"attention:\" , attention.shape)\n",
    "            # print(\"mask:\" , mask)\n",
    "            \n",
    "        \n",
    "        attention = attention.masked_fill(tril[:tokens, :tokens] == 0, float(-1e9))       # Size: [batchSize x tokens x tokens]\n",
    "        # print(\"attention1:\" , attention)\n",
    "        attention = F.softmax(attention, dim=-1)                                            # Size: [batchSize x tokens x tokens]\n",
    "        # print(\"attention2:\" , attention)\n",
    "        attention = self.Dropout(attention)\n",
    "        # print(\"attention3:\" , attention)\n",
    "        \n",
    "        out = attention @ value                                                             # Size: [Batch Size x Tokens Amount x head_size]\n",
    "        # print(\"out:\" , out)\n",
    "        return out                                                                          # Size: [Batch Size x Tokens Amount x head_size]\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads, head_size, dropout, device):\n",
    "        super().__init__()  \n",
    "        self.num_heads  = num_heads\n",
    "        self.head_size  = head_size\n",
    "        self.embed_size = embed_size \n",
    "        self.device     = device\n",
    "        \n",
    "        self.Heads = nn.ModuleList()\n",
    "        for _ in range(num_heads):\n",
    "            self.Heads.append(Head(self.embed_size, self.head_size, dropout, self.device)) # ModuleList Size: [num_heads]\n",
    "\n",
    "        self.Projection = nn.Linear(self.embed_size, self.embed_size)    # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "        self.Dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        multiHead = torch.cat([head(x, mask) for head in self.Heads], dim=-1)  # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "        projection = self.Dropout(self.Projection(multiHead))            # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "        return projection                                                # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, embed_size, dropout):\n",
    "        super().__init__()\n",
    "        self.FeedForward = nn.Sequential(\n",
    "            nn.Linear(embed_size, 4 * embed_size),  # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * embed_size, embed_size),  # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    \n",
    "    def forward(self, attentions):\n",
    "        return self.FeedForward(attentions)\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    def __init__(self,  embed_size, num_heads, head_size, dropout, device):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.num_heads  = num_heads\n",
    "        self.head_size  = head_size\n",
    "        self.device     = device\n",
    "\n",
    "        self.MultiAttentionHeads = MultiHeadAttention(self.embed_size, self.num_heads, self.head_size, dropout, self.device) # Size: [Batch Size x Tokens Amount x head_size]\n",
    "        self.FeedForward         = FeedForward(self.embed_size, dropout)   # Size: [Batch Size x Tokens Amount x head_size]\n",
    "        self.Ln1                 = nn.LayerNorm(self.embed_size)  # Size: [Batch Size x Tokens Amount x head_size]\n",
    "        self.Ln2                 = nn.LayerNorm(self.embed_size)  # Size: [Batch Size x Tokens Amount x head_size]\n",
    "\n",
    "    def forward(self, positionedEmbeddings, mask=None):\n",
    "        attentions  = positionedEmbeddings + self.MultiAttentionHeads(self.Ln1(positionedEmbeddings), mask) # Size: [Batch Size x Tokens Amount x embed_size]. Apply MultiHead Attention Layer\n",
    "        feedForward = attentions + self.FeedForward(self.Ln2(attentions))                             # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "        return feedForward                                                                  # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "        \n",
    "\n",
    "\n",
    "class SimpleTransformer(nn.Module):\n",
    "    def __init__(self, num_heads, embed_size, head_size, input_tokens_amount, vocab_size, dropout, device):\n",
    "        super().__init__()\n",
    "        self.device                 = device\n",
    "        self.embed_size             = embed_size\n",
    "        self.input_tokens_amount    = input_tokens_amount\n",
    "        self.vocab_size             = vocab_size\n",
    "        self.num_heads              = num_heads\n",
    "        self.head_size              = head_size\n",
    "       \n",
    "        self.Embedding = torch.nn.Embedding(num_embeddings = self.vocab_size, embedding_dim = self.embed_size, device = self.device) # Size: [vocab_size x embed_size]\n",
    "\n",
    "        self.Blocks = nn.ModuleList([\n",
    "            Block(self.embed_size, self.num_heads, self.head_size, dropout, self.device) for _ in range(6)\n",
    "        ])\n",
    "        self.final_layer_norm = nn.LayerNorm(self.embed_size)\n",
    "        self.LangModelHead  = nn.Linear(self.embed_size, self.vocab_size, device = self.device) # Size: [embed_size x vocab_size]\n",
    "\n",
    "    \n",
    "    def positionEncoding(self, input_tokens_amount):\n",
    "        positionEncoding = torch.zeros(input_tokens_amount, self.embed_size, device = self.device)                                  # max length x embedding dimmensions equivalent to Size: [input_tokens_amount x embed_size]\n",
    "        positions = torch.arange(0, input_tokens_amount, dtype=torch.float, device = self.device).unsqueeze(1)                      # Tensor [0, 1, 2,..., input_tokens_amount] -> [⋮] : rotated for each value in separate row of 1 column\n",
    "        div_term = torch.exp(torch.arange(0, self.embed_size, 2, device = self.device).float() * (-math.log(10000.0) / self.embed_size)) # Tensor [0, 2, 4,..., embed_size] x (-math.log(10000.0) / self.embed_size) --> exponenta\n",
    "\n",
    "        positionEncoding[:, 0::2] = torch.sin(positions * div_term)             # Size: [input_tokens_amount x embed_size], set the odd values (columns 1 and 3) \n",
    "        positionEncoding[:, 1::2] = torch.cos(positions * div_term)             # Size: [input_tokens_amount x embed_size], set the even values (columns 2 and 4) \n",
    " \n",
    "        return positionEncoding.unsqueeze(0)                                    # Size: [1 (for batch dim) x input_tokens_amount x embed_size]\n",
    "     \n",
    "    def forward(self, input):                                                   # Size: [Batch Size x Tokens Amount] - input\n",
    "        batchSize, tokens    = input.shape\n",
    "\n",
    "        # Creating a mask for padding tokens\n",
    "        # padding_mask = (input != 0).unsqueeze(1).unsqueeze(2).to(device)        # `0` is the padding token id\n",
    "        # padding_mask = (input != 0).unsqueeze(1).to(device)        # `0` is the padding token id\n",
    "\n",
    "        padded_lable = (input != 0).float().to(device)\n",
    "        padding_mask = padded_lable.unsqueeze(-1) @ padded_lable.unsqueeze(-2)\n",
    "        \n",
    "        embeddings           = self.Embedding(input)                            # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "        positionedEmbeddings = embeddings + self.positionEncoding(tokens)       # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "        \n",
    "        blocks = positionedEmbeddings\n",
    "        for block in self.Blocks:\n",
    "            blocks = block(blocks, padding_mask)                                # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "        blocks = self.final_layer_norm(blocks)\n",
    "        \n",
    "        logits = self.LangModelHead(blocks)                                     # Size: [Batch Size x Tokens Amount x vocab_size]\n",
    "        return logits                                                           # Size: [Batch Size x Tokens Amount x vocab_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head_size:  64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batches = 16\n",
    "learning_rate = 1e-4\n",
    "dropout = 0.2\n",
    "maxNewTokens = 200\n",
    "input_tokens_amount = 128\n",
    "vocab_size = sp.GetPieceSize()\n",
    "embed_size = 512 # 512\n",
    "num_heads = 8\n",
    "head_size = int(embed_size / num_heads)\n",
    "print(\"head_size: \", head_size)\n",
    "if embed_size % num_heads != 0:\n",
    "    print(\"embed_size Cannot be divided evenly by num_heads.\")\n",
    "    sys.exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modela and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    inputs, targets = zip(*batch)  # Unzip the batch into inputs and targets\n",
    "\n",
    "    # Pad sequences so they are all the same length\n",
    "    inputs_padded = pad_sequence(inputs, batch_first=True, padding_value=0)\n",
    "    targets_padded = pad_sequence(targets, batch_first=True, padding_value=0)\n",
    "\n",
    "    return inputs_padded, targets_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleTransformer(\n",
    "    embed_size          = embed_size, \n",
    "    num_heads           = num_heads,\n",
    "    head_size           = head_size, \n",
    "    input_tokens_amount = input_tokens_amount, \n",
    "    vocab_size          = vocab_size,\n",
    "    dropout             = dropout,\n",
    "    device              = device,\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "sDataset = StoryDataset(train['text'], sp, input_tokens_amount, device)\n",
    "sDataloader = DataLoader(sDataset, batch_size=batches, shuffle=True, collate_fn=collate_fn, )\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1] Loss: 3.487 Rloss: 0.116\n",
      "[1, 31] Loss: 3.517 Rloss: 3.568\n",
      "[1, 61] Loss: 3.422 Rloss: 3.526\n",
      "[1, 91] Loss: 3.524 Rloss: 3.499\n",
      "[1, 121] Loss: 3.447 Rloss: 3.558\n",
      "[1, 151] Loss: 3.504 Rloss: 3.602\n",
      "[1, 181] Loss: 3.427 Rloss: 3.592\n",
      "[1, 211] Loss: 3.453 Rloss: 3.553\n",
      "[1, 241] Loss: 3.538 Rloss: 3.551\n",
      "[1, 271] Loss: 3.515 Rloss: 3.544\n",
      "[1, 301] Loss: 3.733 Rloss: 3.556\n",
      "[1, 331] Loss: 3.587 Rloss: 3.585\n",
      "[1, 361] Loss: 3.523 Rloss: 3.570\n",
      "[1, 391] Loss: 3.540 Rloss: 3.526\n",
      "[1, 421] Loss: 3.510 Rloss: 3.550\n",
      "[1, 451] Loss: 3.509 Rloss: 3.544\n",
      "[1, 481] Loss: 3.743 Rloss: 3.540\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (stories, targets) in enumerate(sDataloader): # stories Size: [Batch Size x Tokens Amount], targets Size: [Batch Size x Tokens Amount]\n",
    "        logits  = model(stories)                      # Size: [Batch Size x Tokens Amount x Vocab Size]\n",
    "        batch, tokens, vocabs = logits.shape\n",
    "        logits  = logits.view(batch * tokens, vocabs) # Size: [(Batch Size * Tokens Amount) x Vocab Size]\n",
    "        targets = targets.view(batch * tokens)        # Size: [(Batch Size * Tokens Amount)]\n",
    "        \n",
    "        # Assuming outputs from the model and labels are already obtained\n",
    "        mask = targets != 0  # Assuming -1 is used for padding in labels\n",
    "        loss = F.cross_entropy(logits, targets, reduction='none')\n",
    "        loss = loss * mask.view(batch * tokens).float()\n",
    "        loss = loss.sum() / mask.sum()\n",
    "        running_loss += loss.item()\n",
    "        # loss = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad(set_to_none = True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 30 == 0:  # Print loss every 100 batches\n",
    "            print(f'[{epoch + 1}, {batch_idx}] Loss: {loss.item() :.3f} Rloss: {running_loss / 30:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"finish\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finalStory # 0 :  Once upon a time, there was a little boy named Timmy. Timmy loved to jump outside and the game. He was only three years old boy went for the forest. One day, Timmy's mother saw a toy car and his owner that he met a loud pirate said, it. He kept playing in his family. Timmy decided to the forest. Timmy got to catch it was so he lay the colors and started to wear that he could help him feel better that he remembered what is that they went on the cliff where he could not yours!\" But then, even happier and they worked together. Timmy, Timmy was happy. When they had lots of the hole. His mommy explained that he agreed. Later being so surprised and passed. The end of the bunch he was very mild golf. The lion. Timmy and fell asleep. After a beautiful picture's ok. He had a earthquake quickly ran back to clean. After a Lee came that he was a really fun that he told him tight, the rake to do \n",
      "\n",
      "\n",
      "finalStory # 1 :  Once upon a time, there was a little girl named Lily. She loved to play with her toys and play outside. One day, Lily's mommy said they arrived, she took her mommy realized she found some cookies to sit on the book to see to sew, Mommy asked her crayons, \"Why don't find this is so excited and turn the phone to do to go to show the fan remember to punish and they made her about what they knew Lily crawled on the ground. Lily gently said to miss in the iron. They played tag's mom, and clapped money. Lily was very happy to make the play nicely. From then on, Lily and the table. But they look great shampoo she did not scarymarry.</s> she had fun.</s>. Lily was ready to the house. She always keep her nearby. She was going to order and a giraffe's mom. She sighed off the bridge of the wind blew her. She laughed and reached the hospital. She was so shiny. Now they \n",
      "\n",
      "\n",
      "finalStory # 2 :  Once upon a time, there was a little girl called Beth. She was very bossy, she was bowing was enormous and go to sail dough. The little girl had been playing with her friends to hide, but she walked up the train knew it in the earth one of the log stopped. Cynthia. As she looked scared, she had so she could hear it. The little girl were trying away and something unusual jogged Emma ringing it's wish to reply. A confused. But then. They sat down, bright hair! The girl made her flute and she would happen, she knew it was all the flute and laughed as The frog and she was so thankful. Jenny window! She knew it in her family hugged her mum, happy and she had gotten. It was very proud and grabbed the kitchen. She hugged her son was very humble sounds. It's cheap don't budge and higher to separate. The little girl came to start to see the microphone for an x better. Molly were able to do. She \n",
      "\n",
      "\n",
      "finalStory # 3 :  Once upon a time, there was a little girl named Mary. She had a big house with her mommy. The bird was very pretty style. One day, mommy heard a little girl. She saw a deep of a big engine red frog. \"Can I will help me?\" Her brother. The little fish found a while, \"I am hotter night, \"Don't have to love here, daddy,\" she said, \"I will help others and the barber are you. \"Yes, \"That'm sorry. After a bite,\" she needed to visit her joy. She picked her a while they finished a big orange game smiled and happy! She smiled and looked at Jill was beautiful dress again. It was allergic! The butterfly every time, opening played together. The little girl smiled. I have to the top. She looked around the importance the little girl nodded. She screamed.\" Amy'm looking straight. She smiled. \"I'm silly,\" said she went away. But the answer thermometer until \n",
      "\n",
      "\n",
      "finalStory # 4 :  Once upon a time, there was a little boy named Tim. Tim loved to play with his toys through the wind. One day, Tim went to a fun. He wanted to the stone. \"What shall!\" Grandpa asked, \"What's so he noticed that?\" His mommy. Let't want to speed that when he wanted to play, Tim was so he could have such a click is small piece of the rock with his mommy hugged and yummy. They both he could not do it with his toys about his mom said, Tim was very anxious, Tim kept trying to bes very tired. They went back to leave and loved it.</s> for helping them. From then on, \"Can we should run with his wife available and he was happy. But it looked at the boat and make you can. He had been listening.</s> going on, Tim. It makes ever. The he forgot to take his phone. They learned that it for a long time and copy and love, it was a trophy \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for J in range(5):\n",
    "        startPhrase = \"Once upon a time,\"\n",
    "        startTokensIds = sp.EncodeAsIds(startPhrase)[:input_tokens_amount]     # [int, ..., tokens_length] \n",
    "        startTokensTensor = torch.tensor(startTokensIds, dtype=torch.long, device = device).unsqueeze(0)   # [1 x int, ..., tokens_length] \n",
    "        finalStoryTokensIds = startTokensIds\n",
    "    \n",
    "        for i in range(maxNewTokens):\n",
    "            lastTokensInSentence = startTokensTensor[:, -input_tokens_amount:]\n",
    "            genLogits = model(lastTokensInSentence)                         # Size: [Batch Size x Tokens Amount x Vocab Size]\n",
    "    \n",
    "            # Let's focus only on last token in sequence\n",
    "            genLogits = genLogits[:, -1, :]                                 # Size: [Batch Size x Vocab Size]  \n",
    "            probabilities = F.softmax(genLogits, dim=-1)                    # Size: [Batch Size x Vocab Size], Probavilities of each word from vocab\n",
    "            nextIdx = torch.multinomial(probabilities, num_samples = 1)     # Size: [Batch Size x 1]\n",
    "    \n",
    "            # apply running index to the running sequence \n",
    "            startTokensTensor = torch.cat((startTokensTensor, nextIdx), dim=1) # Size: [Batch Size x (Tokens Amount + 1)]\n",
    "            finalStoryTokensIds.append(nextIdx.item())\n",
    "            \n",
    "            finalStoryTokens = []\n",
    "            for tokenId in finalStoryTokensIds:\n",
    "                finalStoryTokens.append(sp.IdToPiece(tokenId))\n",
    "            \n",
    "        finalStory = ''.join(finalStoryTokens).replace('▁', ' ').strip()  # Assuming '▁' is the SentencePiece underline character\n",
    "        print(\"finalStory #\", J, \": \", finalStory, \"\\n\\n\")\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
