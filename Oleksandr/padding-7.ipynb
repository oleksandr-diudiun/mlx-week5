{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (15.0.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.4)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.24.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "! pip install pyarrow matplotlib sentencepiece pandas\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import TransformerDecoder, TransformerDecoderLayer\n",
    "import sentencepiece as spm\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "if torch.backends.mps.is_available():  # Check for Apple Silicon GPU availability (requires PyTorch 1.12 or later)\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():  # Check for NVIDIA GPU availability\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Fall back to CPU\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from both Parquet files\n",
    "train_0 = pd.read_parquet('../train/0000.parquet')\n",
    "train_1 = pd.read_parquet('../train/0001.parquet')\n",
    "train_2 = pd.read_parquet('../train/0002.parquet')\n",
    "train_3 = pd.read_parquet('../train/0003.parquet')\n",
    "\n",
    "# Concatenate the two DataFrames into one\n",
    "train = pd.concat([train_0, train_1, train_2, train_3], ignore_index=True)\n",
    "# train['text'] = train['text'].str.slice(start=0, stop=1500)\n",
    "\n",
    "# Filter out elements with less than 2000 characters\n",
    "# train = train[train['text'].str.len() >= 1500]\n",
    "# Reset the index of the filtered DataFrame and drop the old index\n",
    "# Select only the first 10000 rows\n",
    "train = train.iloc[:1000]\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "print(train.shape)\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load('spm_05_text_model.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoryDataset(Dataset):\n",
    "    def __init__(self, stories,  sp, input_tokens_amount, device):\n",
    "        super().__init__()\n",
    "        self.stories = stories\n",
    "        self.sp = sp\n",
    "        self.input_tokens_amount = input_tokens_amount\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stories)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # encoded_story = [sp.PieceToId('<s>')] + self.sp.EncodeAsIds(self.stories[idx])[:(self.input_tokens_amount-1)]\n",
    "        # encoded_target = self.sp.EncodeAsIds(self.stories[idx])[:(self.input_tokens_amount-1)] + [sp.PieceToId('</s>')]\n",
    "        encoded_story = [sp.PieceToId('<s>')] + self.sp.EncodeAsIds(self.stories[idx])\n",
    "        encoded_target = self.sp.EncodeAsIds(self.stories[idx]) + [sp.PieceToId('</s>')]\n",
    "        return torch.tensor(encoded_story, dtype=torch.long, device = self.device), torch.tensor(encoded_target, dtype=torch.long, device = self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, embed_size, head_size, dropout, device):\n",
    "        super().__init__()\n",
    "        self.head_size      = head_size\n",
    "        self.embed_size     = embed_size\n",
    "        self.device         = device\n",
    "        \n",
    "        self.Key   = nn.Linear(self.embed_size, self.head_size, bias=False, device = self.device) # Size: [embed_size x head_size]\n",
    "        self.Query = nn.Linear(self.embed_size, self.head_size, bias=False, device = self.device) # Size: [embed_size x head_size] \n",
    "        self.Value = nn.Linear(self.embed_size, self.head_size, bias=False, device = self.device) # Size: [embed_size x head_size] \n",
    "        \n",
    "        self.Dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask = None):\n",
    "        batchSize, tokens, head_size = x.shape\n",
    "\n",
    "        key   = self.Key(x)    # Size: [batchSize x tokens x head_size]\n",
    "        query = self.Query(x)  # Size: [batchSize x tokens x head_size]\n",
    "        value = self.Value(x)  # Size: [batchSize x tokens x head_size]\n",
    "\n",
    "        tril = torch.tril(torch.ones(tokens, tokens, device = self.device))                 # Size: [tokens_amount x tokens_amount]. Diagonale ones left side only.                                                                      \n",
    "\n",
    "        # Compute Attention scores (\"Affinities\")\n",
    "        attention = query @ key.transpose(-2, -1) * head_size**0.5                          # [Batch Size x Tokens amount x head_size] @ [Batch Size x head_size x Tokens amount] --> [Batch Size x Tokens amount x Tokens amount]\n",
    "       \n",
    "        if mask is not None:\n",
    "            # print(\"mask:\" , mask.shape)\n",
    "            attention = attention.masked_fill(mask == 0, float(-1e9))                     # Size: [batchSize x tokens x tokens]\n",
    "            # print(\"attention:\" , attention.shape)\n",
    "            # print(\"mask:\" , mask)\n",
    "            \n",
    "        \n",
    "        attention = attention.masked_fill(tril[:tokens, :tokens] == 0, float(-1e9))       # Size: [batchSize x tokens x tokens]\n",
    "        # print(\"attention1:\" , attention)\n",
    "        attention = F.softmax(attention, dim=-1)                                            # Size: [batchSize x tokens x tokens]\n",
    "        # print(\"attention2:\" , attention)\n",
    "        attention = self.Dropout(attention)\n",
    "        # print(\"attention3:\" , attention)\n",
    "        \n",
    "        out = attention @ value                                                             # Size: [Batch Size x Tokens Amount x head_size]\n",
    "        # print(\"out:\" , out)\n",
    "        return out                                                                          # Size: [Batch Size x Tokens Amount x head_size]\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads, head_size, dropout, device):\n",
    "        super().__init__()  \n",
    "        self.num_heads  = num_heads\n",
    "        self.head_size  = head_size\n",
    "        self.embed_size = embed_size \n",
    "        self.device     = device\n",
    "        \n",
    "        self.Heads = nn.ModuleList()\n",
    "        for _ in range(num_heads):\n",
    "            self.Heads.append(Head(self.embed_size, self.head_size, dropout, self.device)) # ModuleList Size: [num_heads]\n",
    "\n",
    "        self.Projection = nn.Linear(self.embed_size, self.embed_size)    # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "        self.Dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        multiHead = torch.cat([head(x, mask) for head in self.Heads], dim=-1)  # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "        projection = self.Dropout(self.Projection(multiHead))            # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "        return projection                                                # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, embed_size, dropout):\n",
    "        super().__init__()\n",
    "        self.FeedForward = nn.Sequential(\n",
    "            nn.Linear(embed_size, 4 * embed_size),  # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * embed_size, embed_size),  # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    \n",
    "    def forward(self, attentions):\n",
    "        return self.FeedForward(attentions)\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    def __init__(self,  embed_size, num_heads, head_size, dropout, device):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.num_heads  = num_heads\n",
    "        self.head_size  = head_size\n",
    "        self.device     = device\n",
    "\n",
    "        self.MultiAttentionHeads = MultiHeadAttention(self.embed_size, self.num_heads, self.head_size, dropout, self.device) # Size: [Batch Size x Tokens Amount x head_size]\n",
    "        self.FeedForward         = FeedForward(self.embed_size, dropout)   # Size: [Batch Size x Tokens Amount x head_size]\n",
    "        self.Ln1                 = nn.LayerNorm(self.embed_size)  # Size: [Batch Size x Tokens Amount x head_size]\n",
    "        self.Ln2                 = nn.LayerNorm(self.embed_size)  # Size: [Batch Size x Tokens Amount x head_size]\n",
    "\n",
    "    def forward(self, positionedEmbeddings, mask=None):\n",
    "        attentions  = positionedEmbeddings + self.MultiAttentionHeads(self.Ln1(positionedEmbeddings), mask) # Size: [Batch Size x Tokens Amount x embed_size]. Apply MultiHead Attention Layer\n",
    "        feedForward = attentions + self.FeedForward(self.Ln2(attentions))                             # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "        return feedForward                                                                  # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "        \n",
    "\n",
    "\n",
    "class SimpleTransformer(nn.Module):\n",
    "    def __init__(self, num_heads, embed_size, head_size, input_tokens_amount, vocab_size, dropout, device):\n",
    "        super().__init__()\n",
    "        self.device                 = device\n",
    "        self.embed_size             = embed_size\n",
    "        self.input_tokens_amount    = input_tokens_amount\n",
    "        self.vocab_size             = vocab_size\n",
    "        self.num_heads              = num_heads\n",
    "        self.head_size              = head_size\n",
    "       \n",
    "        self.Embedding = torch.nn.Embedding(num_embeddings = self.vocab_size, embedding_dim = self.embed_size, device = self.device) # Size: [vocab_size x embed_size]\n",
    "\n",
    "        self.Blocks = nn.ModuleList([\n",
    "            Block(self.embed_size, self.num_heads, self.head_size, dropout, self.device) for _ in range(6)\n",
    "        ])\n",
    "        self.final_layer_norm = nn.LayerNorm(self.embed_size)\n",
    "        self.LangModelHead  = nn.Linear(self.embed_size, self.vocab_size, device = self.device) # Size: [embed_size x vocab_size]\n",
    "\n",
    "    \n",
    "    def positionEncoding(self, input_tokens_amount):\n",
    "        positionEncoding = torch.zeros(input_tokens_amount, self.embed_size, device = self.device)                                  # max length x embedding dimmensions equivalent to Size: [input_tokens_amount x embed_size]\n",
    "        positions = torch.arange(0, input_tokens_amount, dtype=torch.float, device = self.device).unsqueeze(1)                      # Tensor [0, 1, 2,..., input_tokens_amount] -> [⋮] : rotated for each value in separate row of 1 column\n",
    "        div_term = torch.exp(torch.arange(0, self.embed_size, 2, device = self.device).float() * (-math.log(10000.0) / self.embed_size)) # Tensor [0, 2, 4,..., embed_size] x (-math.log(10000.0) / self.embed_size) --> exponenta\n",
    "\n",
    "        positionEncoding[:, 0::2] = torch.sin(positions * div_term)             # Size: [input_tokens_amount x embed_size], set the odd values (columns 1 and 3) \n",
    "        positionEncoding[:, 1::2] = torch.cos(positions * div_term)             # Size: [input_tokens_amount x embed_size], set the even values (columns 2 and 4) \n",
    " \n",
    "        return positionEncoding.unsqueeze(0)                                    # Size: [1 (for batch dim) x input_tokens_amount x embed_size]\n",
    "     \n",
    "    def forward(self, input):                                                   # Size: [Batch Size x Tokens Amount] - input\n",
    "        batchSize, tokens    = input.shape\n",
    "\n",
    "        # Creating a mask for padding tokens\n",
    "        # padding_mask = (input != 0).unsqueeze(1).unsqueeze(2).to(device)        # `0` is the padding token id\n",
    "        # padding_mask = (input != 0).unsqueeze(1).to(device)        # `0` is the padding token id\n",
    "\n",
    "        padded_lable = (input != 0).float().to(device)\n",
    "        padding_mask = padded_lable.unsqueeze(-1) @ padded_lable.unsqueeze(-2)\n",
    "        \n",
    "        embeddings           = self.Embedding(input)                            # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "        positionedEmbeddings = embeddings + self.positionEncoding(tokens)       # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "        \n",
    "        blocks = positionedEmbeddings\n",
    "        for block in self.Blocks:\n",
    "            blocks = block(blocks, padding_mask)                                # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "        blocks = self.final_layer_norm(blocks)\n",
    "        \n",
    "        logits = self.LangModelHead(blocks)                                     # Size: [Batch Size x Tokens Amount x vocab_size]\n",
    "        return logits                                                           # Size: [Batch Size x Tokens Amount x vocab_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head_size:  64\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batches = 16\n",
    "learning_rate = 1e-4\n",
    "dropout = 0.2\n",
    "maxNewTokens = 200\n",
    "input_tokens_amount = 128\n",
    "vocab_size = sp.GetPieceSize()\n",
    "embed_size = 512 # 512\n",
    "num_heads = 8\n",
    "head_size = int(embed_size / num_heads)\n",
    "print(\"head_size: \", head_size)\n",
    "if embed_size % num_heads != 0:\n",
    "    print(\"embed_size Cannot be divided evenly by num_heads.\")\n",
    "    sys.exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modela and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    inputs, targets = zip(*batch)  # Unzip the batch into inputs and targets\n",
    "\n",
    "    # Pad sequences so they are all the same length\n",
    "    inputs_padded = pad_sequence(inputs, batch_first=True, padding_value=0)\n",
    "    targets_padded = pad_sequence(targets, batch_first=True, padding_value=0)\n",
    "\n",
    "    return inputs_padded, targets_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleTransformer(\n",
    "    embed_size          = embed_size, \n",
    "    num_heads           = num_heads,\n",
    "    head_size           = head_size, \n",
    "    input_tokens_amount = input_tokens_amount, \n",
    "    vocab_size          = vocab_size,\n",
    "    dropout             = dropout,\n",
    "    device              = device,\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "sDataset = StoryDataset(train['text'], sp, input_tokens_amount, device)\n",
    "sDataloader = DataLoader(sDataset, batch_size=batches, shuffle=True, collate_fn=collate_fn, )\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, Loss: 1.7032625675201416\n",
      "Epoch: 0, Batch: 30, Loss: 1.6784461736679077\n",
      "Epoch: 0, Batch: 60, Loss: 1.7360411882400513\n",
      "Epoch: 1, Batch: 0, Loss: 1.6547216176986694\n",
      "Epoch: 1, Batch: 30, Loss: 1.730575442314148\n",
      "Epoch: 1, Batch: 60, Loss: 1.6664119958877563\n",
      "Epoch: 2, Batch: 0, Loss: 1.5651731491088867\n",
      "Epoch: 2, Batch: 30, Loss: 1.6843961477279663\n",
      "Epoch: 2, Batch: 60, Loss: 1.6298573017120361\n",
      "Epoch: 3, Batch: 0, Loss: 1.5088417530059814\n",
      "Epoch: 3, Batch: 30, Loss: 1.5732297897338867\n",
      "Epoch: 3, Batch: 60, Loss: 1.5546616315841675\n",
      "Epoch: 4, Batch: 0, Loss: 1.5218991041183472\n",
      "Epoch: 4, Batch: 30, Loss: 1.6012804508209229\n",
      "Epoch: 4, Batch: 60, Loss: 1.5158175230026245\n",
      "Epoch: 5, Batch: 0, Loss: 1.4829210042953491\n",
      "Epoch: 5, Batch: 30, Loss: 1.5876736640930176\n",
      "Epoch: 5, Batch: 60, Loss: 1.5592361688613892\n",
      "Epoch: 6, Batch: 0, Loss: 1.5517034530639648\n",
      "Epoch: 6, Batch: 30, Loss: 1.647222876548767\n",
      "Epoch: 6, Batch: 60, Loss: 1.5731440782546997\n",
      "Epoch: 7, Batch: 0, Loss: 1.5602920055389404\n",
      "Epoch: 7, Batch: 30, Loss: 1.5516897439956665\n",
      "Epoch: 7, Batch: 60, Loss: 1.5180867910385132\n",
      "Epoch: 8, Batch: 0, Loss: 1.5011465549468994\n",
      "Epoch: 8, Batch: 30, Loss: 1.5380011796951294\n",
      "Epoch: 8, Batch: 60, Loss: 1.5826067924499512\n",
      "Epoch: 9, Batch: 0, Loss: 1.509304404258728\n",
      "Epoch: 9, Batch: 30, Loss: 1.509554386138916\n",
      "Epoch: 9, Batch: 60, Loss: 1.5438495874404907\n",
      "Epoch: 10, Batch: 0, Loss: 1.4922051429748535\n",
      "Epoch: 10, Batch: 30, Loss: 1.598214030265808\n",
      "Epoch: 10, Batch: 60, Loss: 1.5844061374664307\n",
      "Epoch: 11, Batch: 0, Loss: 1.5736171007156372\n",
      "Epoch: 11, Batch: 30, Loss: 1.7792831659317017\n",
      "Epoch: 11, Batch: 60, Loss: 1.7400141954421997\n",
      "Epoch: 12, Batch: 0, Loss: 1.681329607963562\n",
      "Epoch: 12, Batch: 30, Loss: 1.6785210371017456\n",
      "Epoch: 12, Batch: 60, Loss: 1.6926485300064087\n",
      "Epoch: 13, Batch: 0, Loss: 1.663017749786377\n",
      "Epoch: 13, Batch: 30, Loss: 1.6884698867797852\n",
      "Epoch: 13, Batch: 60, Loss: 1.8791658878326416\n",
      "Epoch: 14, Batch: 0, Loss: 1.711484432220459\n",
      "Epoch: 14, Batch: 30, Loss: 1.8072309494018555\n",
      "Epoch: 14, Batch: 60, Loss: 1.820684790611267\n",
      "Epoch: 15, Batch: 0, Loss: 1.788988471031189\n",
      "Epoch: 15, Batch: 30, Loss: 1.7274426221847534\n",
      "Epoch: 15, Batch: 60, Loss: 1.704918622970581\n",
      "Epoch: 16, Batch: 0, Loss: 1.5496997833251953\n",
      "Epoch: 16, Batch: 30, Loss: 1.6845581531524658\n",
      "Epoch: 16, Batch: 60, Loss: 1.6685831546783447\n",
      "Epoch: 17, Batch: 0, Loss: 1.6648497581481934\n",
      "Epoch: 17, Batch: 30, Loss: 1.6587213277816772\n",
      "Epoch: 17, Batch: 60, Loss: 1.6933730840682983\n",
      "Epoch: 18, Batch: 0, Loss: 1.573811411857605\n",
      "Epoch: 18, Batch: 30, Loss: 1.7237528562545776\n",
      "Epoch: 18, Batch: 60, Loss: 1.8103870153427124\n",
      "Epoch: 19, Batch: 0, Loss: 1.678107738494873\n",
      "Epoch: 19, Batch: 30, Loss: 1.7849481105804443\n",
      "Epoch: 19, Batch: 60, Loss: 1.7932260036468506\n",
      "Epoch: 20, Batch: 0, Loss: 1.6517045497894287\n",
      "Epoch: 20, Batch: 30, Loss: 1.6605015993118286\n",
      "Epoch: 20, Batch: 60, Loss: 1.6790205240249634\n",
      "Epoch: 21, Batch: 0, Loss: 1.6349711418151855\n",
      "Epoch: 21, Batch: 30, Loss: 1.642318844795227\n",
      "Epoch: 21, Batch: 60, Loss: 1.7161890268325806\n",
      "Epoch: 22, Batch: 0, Loss: 1.527854084968567\n",
      "Epoch: 22, Batch: 30, Loss: 1.636346459388733\n",
      "Epoch: 22, Batch: 60, Loss: 1.6445207595825195\n",
      "Epoch: 23, Batch: 0, Loss: 1.5567221641540527\n",
      "Epoch: 23, Batch: 30, Loss: 1.5953962802886963\n",
      "Epoch: 23, Batch: 60, Loss: 1.6409672498703003\n",
      "Epoch: 24, Batch: 0, Loss: 1.60695481300354\n",
      "Epoch: 24, Batch: 30, Loss: 1.6341701745986938\n",
      "Epoch: 24, Batch: 60, Loss: 1.670037031173706\n",
      "Epoch: 25, Batch: 0, Loss: 1.7505981922149658\n",
      "Epoch: 25, Batch: 30, Loss: 1.6638679504394531\n",
      "Epoch: 25, Batch: 60, Loss: 1.7263959646224976\n",
      "Epoch: 26, Batch: 0, Loss: 1.564305067062378\n",
      "Epoch: 26, Batch: 30, Loss: 1.6642979383468628\n",
      "Epoch: 26, Batch: 60, Loss: 1.6681729555130005\n",
      "Epoch: 27, Batch: 0, Loss: 1.6052278280258179\n",
      "Epoch: 27, Batch: 30, Loss: 1.622341275215149\n",
      "Epoch: 27, Batch: 60, Loss: 1.5112272500991821\n",
      "Epoch: 28, Batch: 0, Loss: 1.5228444337844849\n",
      "Epoch: 28, Batch: 30, Loss: 1.4820674657821655\n",
      "Epoch: 28, Batch: 60, Loss: 1.5556538105010986\n",
      "Epoch: 29, Batch: 0, Loss: 1.5209953784942627\n",
      "Epoch: 29, Batch: 30, Loss: 1.5970122814178467\n",
      "Epoch: 29, Batch: 60, Loss: 1.592893123626709\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (stories, targets) in enumerate(sDataloader): # stories Size: [Batch Size x Tokens Amount], targets Size: [Batch Size x Tokens Amount]\n",
    "        logits  = model(stories)                      # Size: [Batch Size x Tokens Amount x Vocab Size]\n",
    "        batch, tokens, vocabs = logits.shape\n",
    "        logits  = logits.view(batch * tokens, vocabs) # Size: [(Batch Size * Tokens Amount) x Vocab Size]\n",
    "        targets = targets.view(batch * tokens)        # Size: [(Batch Size * Tokens Amount)]\n",
    "        \n",
    "        # Assuming outputs from the model and labels are already obtained\n",
    "        mask = targets != 0  # Assuming -1 is used for padding in labels\n",
    "        loss = F.cross_entropy(logits, targets, reduction='none')\n",
    "        loss = loss * mask.view(batch * tokens).float()\n",
    "        loss = loss.sum() / mask.sum()\n",
    "        # loss = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad(set_to_none = True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 30 == 0:  # Print loss every 100 batches\n",
    "            print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item()}')\n",
    "print(\"finish\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finalStory # 0 :  Once upon a time, there lived a girl named Lily. She loved to play the woods. One day, she was lost in the mud. While playing with the curtains in her mom asked the table. Lily. Lily went to mail it so she swings. \"Hi, I found your medicine!\" Her mom, but she found it.\" Lily didn't listen and found it first before you help search for her and said. We need you can make your own music with the dictionary again, no!\" Lily't bother your toy. It tasted it's friend to scatter the kitchen. She looked interesting bad things from Lily't give her mom was very nice,\" she had fun. She said, thank you came back to tell the plate to the park. She looked confused. Her mom was safe. They saw a beautiful and the next. She gave her mom had worked. She gave her friends!\" They laughed and said, \"Why do it. She said. She gave Molly. He invited them back \n",
      "\n",
      "\n",
      "finalStory # 1 :  Once upon a time, there was a little girl named Lily. Then she loved to play with her toys. One day, she knew about a big raft. But when she saw that they opened it, Lily was so she really hard on her favorite grandma made them to play with your teddy bear. She said it tightly and Lily started to rest of her mom. Later that she was firm. But her and said, they could stay here.\" But then she put the storm coming from the cookies with a man safe for little brother might be brave and told him clean and said they found it's face.</s>. Lily smiled and make it's house. After her lesson and said, \"No, \"No, \"Yes, sweetie?\" the freezer again,\" she said, it was still a code and said softly. \"Yes, \"Yes, \"That's look! You have your bike and said, \"Yes, I am a stuffed animal and she could do you want to make my diary. She \n",
      "\n",
      "\n",
      "finalStory # 2 :  Once upon a time, there was a little girl named Lily. She had a long time with her toys every day. One day, she was playing, she went to clean the mud. Lily's mommy came to play instead. Lily wasn't have to step on her some cookies and it. When she knew she didn't reach the food - spaghetti to resist, Lily was happy to rub the loving mommy was amazed when they could go to clean up the witch. It was wrong. They both fought for a solution it was gone. So, they could help them to learn new toy and Lily and go inside to help and she found the ball back to keep her mom't have another roar. Then, Lily saw. She raised the sea. Lily was so bad!\" Lily't for lunch!\" Ben were scared. He was sad and hugged her stop the hospital. She held the next. She felt sad. She hugged him clean it. But it up. She started to have fun. Lily woke \n",
      "\n",
      "\n",
      "finalStory # 3 :  Once upon a time, there was a little girl named Lily. She loved to play outside and play with her dog't have fun day. One day, she was scared. She went inside the mud. But when she found a beautiful butterfly. Lily took a scary and didn's mommy said, and they might be scary the basket to be brave and didn't listen. When they went outside to help clean it was so she was so she found it to play instead. So, Lily was excited and asked her mommy asked her grandma started to eat it - a beautiful butterfly and her grandma had seen. She told her grandma quickly continued to the children. She closed her and the kids. She learned that she could be dangerous. She threw away. She couldn't wait to get rid of the butterfly, but she wanted to see her sack first before. Lily't have fun. After a silly, and for her teacher told the kids they started to cry. She had to cry and gave her teacher walked \n",
      "\n",
      "\n",
      "finalStory # 4 :  Once upon a time, there was a little girl named Lily. She loved to play with her toys until she loved to play outside. One day, she wanted to send the table. So, \"Lily, they started to play instead. Lily felt sad because they arrived, but it to wear it's little children!\" started to clean the monster barked at the table. He didn's mom said, but I get it't value tea as much fun game and saw a bath.\" Lily felt sad and went back to deliver the day, \"Mom, but Lily. I found it is my toys for a dead. I won'll take your teddy bear roared and a moment and made a moment and angry. \"Let's fixed,\" Lily said. They continued playing for a code! They smiled and brave. \"Me too.\" They worked together. You are kings and enjoyed their tea party together. Do you want some more. \"You can take a big blanket on the next day on, and sleepy \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for J in range(5):\n",
    "        startPhrase = \"Once upon a time,\"\n",
    "        startTokensIds = sp.EncodeAsIds(startPhrase)[:input_tokens_amount]     # [int, ..., tokens_length] \n",
    "        startTokensTensor = torch.tensor(startTokensIds, dtype=torch.long, device = device).unsqueeze(0)   # [1 x int, ..., tokens_length] \n",
    "        finalStoryTokensIds = startTokensIds\n",
    "    \n",
    "        for i in range(maxNewTokens):\n",
    "            lastTokensInSentence = startTokensTensor[:, -input_tokens_amount:]\n",
    "            genLogits = model(lastTokensInSentence)                         # Size: [Batch Size x Tokens Amount x Vocab Size]\n",
    "    \n",
    "            # Let's focus only on last token in sequence\n",
    "            genLogits = genLogits[:, -1, :]                                 # Size: [Batch Size x Vocab Size]  \n",
    "            probabilities = F.softmax(genLogits, dim=-1)                    # Size: [Batch Size x Vocab Size], Probavilities of each word from vocab\n",
    "            nextIdx = torch.multinomial(probabilities, num_samples = 1)     # Size: [Batch Size x 1]\n",
    "    \n",
    "            # apply running index to the running sequence \n",
    "            startTokensTensor = torch.cat((startTokensTensor, nextIdx), dim=1) # Size: [Batch Size x (Tokens Amount + 1)]\n",
    "            finalStoryTokensIds.append(nextIdx.item())\n",
    "            \n",
    "            finalStoryTokens = []\n",
    "            for tokenId in finalStoryTokensIds:\n",
    "                finalStoryTokens.append(sp.IdToPiece(tokenId))\n",
    "            \n",
    "        finalStory = ''.join(finalStoryTokens).replace('▁', ' ').strip()  # Assuming '▁' is the SentencePiece underline character\n",
    "        print(\"finalStory #\", J, \": \", finalStory, \"\\n\\n\")\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
