{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (15.0.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.4)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.24.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "! pip install pyarrow matplotlib sentencepiece pandas\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import TransformerDecoder, TransformerDecoderLayer\n",
    "import sentencepiece as spm\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn.functional as F\n",
    "\n",
    "if torch.backends.mps.is_available():  # Check for Apple Silicon GPU availability (requires PyTorch 1.12 or later)\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():  # Check for NVIDIA GPU availability\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # Fall back to CPU\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from both Parquet files\n",
    "train_0 = pd.read_parquet('../train/0000.parquet')\n",
    "train_1 = pd.read_parquet('../train/0001.parquet')\n",
    "train_2 = pd.read_parquet('../train/0002.parquet')\n",
    "train_3 = pd.read_parquet('../train/0003.parquet')\n",
    "\n",
    "# Concatenate the two DataFrames into one\n",
    "train = pd.concat([train_0, train_1, train_2, train_3], ignore_index=True)\n",
    "# train['text'] = train['text'].str.slice(start=0, stop=1500)\n",
    "\n",
    "# Filter out elements with less than 2000 characters\n",
    "# train = train[train['text'].str.len() >= 1500]\n",
    "# Reset the index of the filtered DataFrame and drop the old index\n",
    "# Select only the first 10000 rows\n",
    "train = train.iloc[:1000]\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "print(train.shape)\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load('spm_05_text_model.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoryDataset(Dataset):\n",
    "    def __init__(self, stories,  sp, input_tokens_amount, device):\n",
    "        super().__init__()\n",
    "        self.stories = stories\n",
    "        self.sp = sp\n",
    "        self.input_tokens_amount = input_tokens_amount\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stories)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # encoded_story = [sp.PieceToId('<s>')] + self.sp.EncodeAsIds(self.stories[idx])[:(self.input_tokens_amount-1)]\n",
    "        # encoded_target = self.sp.EncodeAsIds(self.stories[idx])[:(self.input_tokens_amount-1)] + [sp.PieceToId('</s>')]\n",
    "        encoded_story = [sp.PieceToId('<s>')] + self.sp.EncodeAsIds(self.stories[idx])\n",
    "        encoded_target = self.sp.EncodeAsIds(self.stories[idx]) + [sp.PieceToId('</s>')]\n",
    "        return torch.tensor(encoded_story, dtype=torch.long, device = self.device), torch.tensor(encoded_target, dtype=torch.long, device = self.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, embed_size, head_size, dropout, device):\n",
    "        super().__init__()\n",
    "        self.head_size      = head_size\n",
    "        self.embed_size     = embed_size\n",
    "        self.device         = device\n",
    "        \n",
    "        self.Key   = nn.Linear(self.embed_size, self.head_size, bias=False, device = self.device) # Size: [embed_size x head_size]\n",
    "        self.Query = nn.Linear(self.embed_size, self.head_size, bias=False, device = self.device) # Size: [embed_size x head_size] \n",
    "        self.Value = nn.Linear(self.embed_size, self.head_size, bias=False, device = self.device) # Size: [embed_size x head_size] \n",
    "        \n",
    "        self.Dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask = None):\n",
    "        batchSize, tokens, head_size = x.shape\n",
    "\n",
    "        key   = self.Key(x)    # Size: [batchSize x tokens x head_size]\n",
    "        query = self.Query(x)  # Size: [batchSize x tokens x head_size]\n",
    "        value = self.Value(x)  # Size: [batchSize x tokens x head_size]\n",
    "\n",
    "        tril = torch.tril(torch.ones(tokens, tokens, device = self.device))                 # Size: [tokens_amount x tokens_amount]. Diagonale ones left side only.                                                                      \n",
    "\n",
    "        # Compute Attention scores (\"Affinities\")\n",
    "        attention = query @ key.transpose(-2, -1) * head_size**0.5                          # [Batch Size x Tokens amount x head_size] @ [Batch Size x head_size x Tokens amount] --> [Batch Size x Tokens amount x Tokens amount]\n",
    "       \n",
    "        # print(\"attention before applying padding mask: \", attention.shape)\n",
    "       \n",
    "        if mask is not None:\n",
    "            # print(\"padding mask inside: \", mask.shape)\n",
    "            attention1 = attention.masked_fill(mask == 0, float('-inf'))                     # Size: [batchSize x tokens x tokens]\n",
    "           \n",
    "            # print(\"attention after applying padding mask: \", attention1.shape)\n",
    "        \n",
    "        attention = attention.masked_fill(tril[:tokens, :tokens] == 0, float('-inf'))       # Size: [batchSize x tokens x tokens]\n",
    "        attention = F.softmax(attention, dim=-1)                                            # Size: [batchSize x tokens x tokens]\n",
    "        attention = self.Dropout(attention)\n",
    "        \n",
    "        out = attention @ value                                                             # Size: [Batch Size x Tokens Amount x head_size]\n",
    "        return out                                                                          # Size: [Batch Size x Tokens Amount x head_size]\n",
    "    \n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_size, num_heads, head_size, dropout, device):\n",
    "        super().__init__()  \n",
    "        self.num_heads  = num_heads\n",
    "        self.head_size  = head_size\n",
    "        self.embed_size = embed_size \n",
    "        self.device     = device\n",
    "        \n",
    "        self.Heads = nn.ModuleList()\n",
    "        for _ in range(num_heads):\n",
    "            self.Heads.append(Head(self.embed_size, self.head_size, dropout, self.device)) # ModuleList Size: [num_heads]\n",
    "\n",
    "        self.Projection = nn.Linear(self.embed_size, self.embed_size)    # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "        self.Dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        multiHead = torch.cat([head(x, mask) for head in self.Heads], dim=-1)  # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "        projection = self.Dropout(self.Projection(multiHead))            # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "        return projection                                                # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, embed_size, dropout):\n",
    "        super().__init__()\n",
    "        self.FeedForward = nn.Sequential(\n",
    "            nn.Linear(embed_size, 4 * embed_size),  # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * embed_size, embed_size),  # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    \n",
    "    def forward(self, attentions):\n",
    "        return self.FeedForward(attentions)\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    def __init__(self,  embed_size, num_heads, head_size, dropout, device):\n",
    "        super().__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.num_heads  = num_heads\n",
    "        self.head_size  = head_size\n",
    "        self.device     = device\n",
    "\n",
    "        self.MultiAttentionHeads = MultiHeadAttention(self.embed_size, self.num_heads, self.head_size, dropout, self.device) # Size: [Batch Size x Tokens Amount x head_size]\n",
    "        self.FeedForward         = FeedForward(self.embed_size, dropout)   # Size: [Batch Size x Tokens Amount x head_size]\n",
    "        self.Ln1                 = nn.LayerNorm(self.embed_size)  # Size: [Batch Size x Tokens Amount x head_size]\n",
    "        self.Ln2                 = nn.LayerNorm(self.embed_size)  # Size: [Batch Size x Tokens Amount x head_size]\n",
    "\n",
    "    def forward(self, positionedEmbeddings, mask=None):\n",
    "        attentions  = positionedEmbeddings + self.MultiAttentionHeads(self.Ln1(positionedEmbeddings), mask) # Size: [Batch Size x Tokens Amount x embed_size]. Apply MultiHead Attention Layer\n",
    "        feedForward = attentions + self.FeedForward(self.Ln2(attentions))                             # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "        return feedForward                                                                  # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "        \n",
    "\n",
    "\n",
    "class SimpleTransformer(nn.Module):\n",
    "    def __init__(self, num_heads, embed_size, head_size, input_tokens_amount, vocab_size, dropout, device):\n",
    "        super().__init__()\n",
    "        self.device                 = device\n",
    "        self.embed_size             = embed_size\n",
    "        self.input_tokens_amount    = input_tokens_amount\n",
    "        self.vocab_size             = vocab_size\n",
    "        self.num_heads              = num_heads\n",
    "        self.head_size              = head_size\n",
    "       \n",
    "        self.Embedding = torch.nn.Embedding(num_embeddings = self.vocab_size, embedding_dim = self.embed_size, device = self.device) # Size: [vocab_size x embed_size]\n",
    "\n",
    "        self.Blocks = nn.ModuleList([\n",
    "            Block(self.embed_size, self.num_heads, self.head_size, dropout, self.device) for _ in range(6)\n",
    "        ])\n",
    "        self.final_layer_norm = nn.LayerNorm(self.embed_size)\n",
    "        self.LangModelHead  = nn.Linear(self.embed_size, self.vocab_size, device = self.device) # Size: [embed_size x vocab_size]\n",
    "\n",
    "    \n",
    "    def positionEncoding(self, input_tokens_amount):\n",
    "        positionEncoding = torch.zeros(input_tokens_amount, self.embed_size, device = self.device)                                  # max length x embedding dimmensions equivalent to Size: [input_tokens_amount x embed_size]\n",
    "        positions = torch.arange(0, input_tokens_amount, dtype=torch.float, device = self.device).unsqueeze(1)                      # Tensor [0, 1, 2,..., input_tokens_amount] -> [⋮] : rotated for each value in separate row of 1 column\n",
    "        div_term = torch.exp(torch.arange(0, self.embed_size, 2, device = self.device).float() * (-math.log(10000.0) / self.embed_size)) # Tensor [0, 2, 4,..., embed_size] x (-math.log(10000.0) / self.embed_size) --> exponenta\n",
    "\n",
    "        positionEncoding[:, 0::2] = torch.sin(positions * div_term)             # Size: [input_tokens_amount x embed_size], set the odd values (columns 1 and 3) \n",
    "        positionEncoding[:, 1::2] = torch.cos(positions * div_term)             # Size: [input_tokens_amount x embed_size], set the even values (columns 2 and 4) \n",
    " \n",
    "        return positionEncoding.unsqueeze(0)                                    # Size: [1 (for batch dim) x input_tokens_amount x embed_size]\n",
    "     \n",
    "    def forward(self, input):                                                   # Size: [Batch Size x Tokens Amount] - input\n",
    "        batchSize, tokens    = input.shape\n",
    "\n",
    "         # Creating a mask for padding tokens\n",
    "        # padding_mask = (input != 0).unsqueeze(1).unsqueeze(2).to(device)        # `0` is the padding token id\n",
    "        padding_mask = (input != 0).unsqueeze(1).to(device)        # `0` is the padding token id\n",
    "        embeddings           = self.Embedding(input)                            # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "        positionedEmbeddings = embeddings + self.positionEncoding(tokens)       # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "        \n",
    "        blocks = positionedEmbeddings\n",
    "        for block in self.Blocks:\n",
    "            blocks = block(blocks, padding_mask)                                # Size: [Batch Size x Tokens Amount x embed_size]\n",
    "        blocks = self.final_layer_norm(blocks)\n",
    "        \n",
    "        logits = self.LangModelHead(blocks)                                     # Size: [Batch Size x Tokens Amount x vocab_size]\n",
    "        return logits                                                           # Size: [Batch Size x Tokens Amount x vocab_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head_size:  64\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "batches = 16\n",
    "learning_rate = 1e-4\n",
    "dropout = 0.2\n",
    "maxNewTokens = 200\n",
    "input_tokens_amount = 128\n",
    "vocab_size = sp.GetPieceSize()\n",
    "embed_size = 512 # 512\n",
    "num_heads = 8\n",
    "head_size = int(embed_size / num_heads)\n",
    "print(\"head_size: \", head_size)\n",
    "if embed_size % num_heads != 0:\n",
    "    print(\"embed_size Cannot be divided evenly by num_heads.\")\n",
    "    sys.exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modela and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    inputs, targets = zip(*batch)  # Unzip the batch into inputs and targets\n",
    "\n",
    "    # Pad sequences so they are all the same length\n",
    "    inputs_padded = pad_sequence(inputs, batch_first=True, padding_value=0)\n",
    "    targets_padded = pad_sequence(targets, batch_first=True, padding_value=0)\n",
    "\n",
    "    return inputs_padded, targets_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleTransformer(\n",
    "    embed_size          = embed_size, \n",
    "    num_heads           = num_heads,\n",
    "    head_size           = head_size, \n",
    "    input_tokens_amount = input_tokens_amount, \n",
    "    vocab_size          = vocab_size,\n",
    "    dropout             = dropout,\n",
    "    device              = device,\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "sDataset = StoryDataset(train['text'], sp, input_tokens_amount, device)\n",
    "sDataloader = DataLoader(sDataset, batch_size=batches, shuffle=True, collate_fn=collate_fn, )\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, Loss: 10.201287269592285\n",
      "Epoch: 0, Batch: 30, Loss: 5.31044864654541\n",
      "Epoch: 0, Batch: 60, Loss: 2.5615382194519043\n",
      "Epoch: 1, Batch: 0, Loss: 4.1097798347473145\n",
      "Epoch: 1, Batch: 30, Loss: 2.217024564743042\n",
      "Epoch: 1, Batch: 60, Loss: 2.318244218826294\n",
      "Epoch: 2, Batch: 0, Loss: 3.1284916400909424\n",
      "Epoch: 2, Batch: 30, Loss: 2.6167635917663574\n",
      "Epoch: 2, Batch: 60, Loss: 2.771216630935669\n",
      "Epoch: 3, Batch: 0, Loss: 2.6451172828674316\n",
      "Epoch: 3, Batch: 30, Loss: 2.2001326084136963\n",
      "Epoch: 3, Batch: 60, Loss: 2.9069747924804688\n",
      "Epoch: 4, Batch: 0, Loss: 2.7433230876922607\n",
      "Epoch: 4, Batch: 30, Loss: 2.2664804458618164\n",
      "Epoch: 4, Batch: 60, Loss: 3.784141778945923\n",
      "Epoch: 5, Batch: 0, Loss: 1.5561466217041016\n",
      "Epoch: 5, Batch: 30, Loss: 2.172642469406128\n",
      "Epoch: 5, Batch: 60, Loss: 2.339362621307373\n",
      "Epoch: 6, Batch: 0, Loss: 1.7275668382644653\n",
      "Epoch: 6, Batch: 30, Loss: 2.0694408416748047\n",
      "Epoch: 6, Batch: 60, Loss: 2.5841124057769775\n",
      "Epoch: 7, Batch: 0, Loss: 1.4094732999801636\n",
      "Epoch: 7, Batch: 30, Loss: 1.4363741874694824\n",
      "Epoch: 7, Batch: 60, Loss: 3.292217969894409\n",
      "Epoch: 8, Batch: 0, Loss: 2.5879642963409424\n",
      "Epoch: 8, Batch: 30, Loss: 1.9016022682189941\n",
      "Epoch: 8, Batch: 60, Loss: 2.693067789077759\n",
      "Epoch: 9, Batch: 0, Loss: 2.0999603271484375\n",
      "Epoch: 9, Batch: 30, Loss: 2.2346904277801514\n",
      "Epoch: 9, Batch: 60, Loss: 1.7387319803237915\n",
      "Epoch: 10, Batch: 0, Loss: 1.9347796440124512\n",
      "Epoch: 10, Batch: 30, Loss: 1.8346606492996216\n",
      "Epoch: 10, Batch: 60, Loss: 1.2437466382980347\n",
      "Epoch: 11, Batch: 0, Loss: 2.500044345855713\n",
      "Epoch: 11, Batch: 30, Loss: 1.2337312698364258\n",
      "Epoch: 11, Batch: 60, Loss: 2.4361565113067627\n",
      "Epoch: 12, Batch: 0, Loss: 2.171811580657959\n",
      "Epoch: 12, Batch: 30, Loss: 2.6244468688964844\n",
      "Epoch: 12, Batch: 60, Loss: 1.855208158493042\n",
      "Epoch: 13, Batch: 0, Loss: 1.5050113201141357\n",
      "Epoch: 13, Batch: 30, Loss: 1.6509402990341187\n",
      "Epoch: 13, Batch: 60, Loss: 2.9305050373077393\n",
      "Epoch: 14, Batch: 0, Loss: 1.8552011251449585\n",
      "Epoch: 14, Batch: 30, Loss: 1.1022294759750366\n",
      "Epoch: 14, Batch: 60, Loss: 2.707595109939575\n",
      "Epoch: 15, Batch: 0, Loss: 2.6683108806610107\n",
      "Epoch: 15, Batch: 30, Loss: 1.7824121713638306\n",
      "Epoch: 15, Batch: 60, Loss: 1.1279585361480713\n",
      "Epoch: 16, Batch: 0, Loss: 1.7303063869476318\n",
      "Epoch: 16, Batch: 30, Loss: 1.7164227962493896\n",
      "Epoch: 16, Batch: 60, Loss: 1.8561924695968628\n",
      "Epoch: 17, Batch: 0, Loss: 1.738173246383667\n",
      "Epoch: 17, Batch: 30, Loss: 1.7605191469192505\n",
      "Epoch: 17, Batch: 60, Loss: 2.037675619125366\n",
      "Epoch: 18, Batch: 0, Loss: 1.5679682493209839\n",
      "Epoch: 18, Batch: 30, Loss: 1.5353894233703613\n",
      "Epoch: 18, Batch: 60, Loss: 1.1633305549621582\n",
      "Epoch: 19, Batch: 0, Loss: 1.8752745389938354\n",
      "Epoch: 19, Batch: 30, Loss: 1.841883897781372\n",
      "Epoch: 19, Batch: 60, Loss: 2.009351968765259\n",
      "Epoch: 20, Batch: 0, Loss: 1.7982959747314453\n",
      "Epoch: 20, Batch: 30, Loss: 1.5584269762039185\n",
      "Epoch: 20, Batch: 60, Loss: 2.0335052013397217\n",
      "Epoch: 21, Batch: 0, Loss: 2.856184720993042\n",
      "Epoch: 21, Batch: 30, Loss: 1.4254240989685059\n",
      "Epoch: 21, Batch: 60, Loss: 1.5478413105010986\n",
      "Epoch: 22, Batch: 0, Loss: 1.6491711139678955\n",
      "Epoch: 22, Batch: 30, Loss: 1.6949807405471802\n",
      "Epoch: 22, Batch: 60, Loss: 1.4826135635375977\n",
      "Epoch: 23, Batch: 0, Loss: 2.0575931072235107\n",
      "Epoch: 23, Batch: 30, Loss: 1.647968053817749\n",
      "Epoch: 23, Batch: 60, Loss: 1.2882450819015503\n",
      "Epoch: 24, Batch: 0, Loss: 1.4389625787734985\n",
      "Epoch: 24, Batch: 30, Loss: 1.7210673093795776\n",
      "Epoch: 24, Batch: 60, Loss: 2.1508052349090576\n",
      "Epoch: 25, Batch: 0, Loss: 2.2231757640838623\n",
      "Epoch: 25, Batch: 30, Loss: 1.5387688875198364\n",
      "Epoch: 25, Batch: 60, Loss: 1.9985325336456299\n",
      "Epoch: 26, Batch: 0, Loss: 2.217024564743042\n",
      "Epoch: 26, Batch: 30, Loss: 1.5982801914215088\n",
      "Epoch: 26, Batch: 60, Loss: 1.6204372644424438\n",
      "Epoch: 27, Batch: 0, Loss: 1.5359927415847778\n",
      "Epoch: 27, Batch: 30, Loss: 1.372752070426941\n",
      "Epoch: 27, Batch: 60, Loss: 1.880018711090088\n",
      "Epoch: 28, Batch: 0, Loss: 2.2422337532043457\n",
      "Epoch: 28, Batch: 30, Loss: 2.6153368949890137\n",
      "Epoch: 28, Batch: 60, Loss: 1.8343945741653442\n",
      "Epoch: 29, Batch: 0, Loss: 2.056816577911377\n",
      "Epoch: 29, Batch: 30, Loss: 1.7078477144241333\n",
      "Epoch: 29, Batch: 60, Loss: 1.4850399494171143\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (stories, targets) in enumerate(sDataloader): # stories Size: [Batch Size x Tokens Amount], targets Size: [Batch Size x Tokens Amount]\n",
    "        logits  = model(stories)                      # Size: [Batch Size x Tokens Amount x Vocab Size]\n",
    "        batch, tokens, vocabs = logits.shape\n",
    "        logits  = logits.view(batch * tokens, vocabs) # Size: [(Batch Size * Tokens Amount) x Vocab Size]\n",
    "        targets = targets.view(batch * tokens)        # Size: [(Batch Size * Tokens Amount)]\n",
    "        \n",
    "        # Assuming outputs from the model and labels are already obtained\n",
    "        # mask = targets != 0  # Assuming -1 is used for padding in labels\n",
    "        # loss = F.cross_entropy(logits, targets, reduction='none')\n",
    "        # loss = loss * mask.view(batch * tokens).float()\n",
    "        # loss = loss.sum() / mask.sum()\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        optimizer.zero_grad(set_to_none = True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 30 == 0:  # Print loss every 100 batches\n",
    "            print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item()}')\n",
    "print(\"finish\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finalStory # 0 :  Once apon a time, upon a little girl named Lila named Molly. One day, her teddy bear was very high in her garden on her plants in her garden. With a while, she saw a soft gust, was very jealous, a classroom - a surprise. She looked from her balloons in her and saw a wanted to school every day, the plant in the flowers. She picked up your vest. She said, \"Boo and said, it for something seems down and said they got her school!\" Her mom hears him my truck. After a rest to her way.\" At neighbourhood reminded no here flew away, \"Please a skip and how before, suddenly was so sleepy wriggling separated. One brightly better. After and cozy in the shopkeeper. But the little kids inside and reliable. \"Look, the bell maybe, but she saw a huge no giant of colorful her. \"Well to come at the barrel. \"Hello, the powder! Many pictures back to help me here and couldn's mom. You can' \n",
      "\n",
      "\n",
      "finalStory # 1 :  Once apon a time, there was a rough as his crown. Timmy loved to play with it is happy that day, Joe was doing books. One day, his mom went outside and started to move. Timmy had to the heel he found a big rainbow, Timmy didn't want to his friends. The little boy said, if he said, Elly. Tim started to move. Timmy's help. The bird bigger and decided to cry to him works. Timmy taught the ball on his black, Timmy looked around the swings. Timmy thanked his leg and planes. reunited the gate of healing, this true. Finally, and thanked the butterfly with the birds. It sounded with different they learned many wishing and turned out to pick it. John fell asleep and seek and said they ago machine was a long time to eat coloured to throw amazement again, but they hadn did not know out the cat, \"Good? close to the house. Let wasn't a bit big box, but then he would take a while, \n",
      "\n",
      "\n",
      "finalStory # 2 :  Once apon a time, there was a little mouse who loved to make Brownie on a little girl named tea. One day, a pink. She wanted to play a special, she so excited for many castle, Jane went home, there was very upset. She felt so she went to suffer pressed instead. It was so that day, â€œDo they laughed under his magical. When they got to the coin. The girl started to go home. On this!\" The little girl discovered a long time. Everything all!</s> of the house and said, â€TMs stop and returned to help. She waved goodbye to the secret to open\". I sad and taller, \"Let't believe, \"Maybe we can be so much long time Sarah were so cake the mixerachel smiled, \"This is the little boy jumped up in a plan cheered that the stairs on, but me,\" they kicked out a surprise. It was able to behave and say, as big smile and started to stay blowing that day, one of \n",
      "\n",
      "\n",
      "finalStory # 3 :  Once apon a time, there was a old girl named Claire driver. She loved to owner. One day, the grass. Jacky. Daisy's ever seen a box songs other animals, and made a furniture. Suddenly, accidents with the lazy of the garage. Sometimes children, but Lily put it out a big and it was out of the garden, but she wanted it glowed and quickly carefully meets yet. She liked to the forest and fluffy. She was learning it barked. She wished it found a note, \"Hey in it up out some fun. She drank, \"I can'm going to help and said no longer water. She said. \"Me ugly, but learned something caring and the side a loud noise.\" The rabbit was sad. They both dead.\" The turtle and spread it on the freezer on a good. The two friends. A own! You will take my doll to a scary clothes that day, said, showing remember Fin and hugged them politely, bravo. She put on the bush. \n",
      "\n",
      "\n",
      "finalStory # 4 :  Once apon a time, there was a little girl named Lily. One day, we get the little world and seek. One day, Lily and bent. Don's mom who had an idea. Every day, they went to get her mom and told him with a shopkeeper anything. \"Lily, \"Come on a great picture of a thin did you this?\" Lily felt happy. Lily's messy to dance!\" Lily thought for your pleasure and this tiny ring the bird. They sat down and said that sometimes they were so surprised. Tommy gave the supermarket smiled at the park and the secret play together and have to throw some dogs as a few minutes, but the floor what she has a big tree. Then, Mommy, this snake that Lily thought they could see marry, Lily back to show her mom told her knee and had an exciting care of excitement. She remembers was so orange time, it was a game but she quickly forgot to dance in the warm cute. She started to see what to offer and started to \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for J in range(5):\n",
    "        startPhrase = \"Once apon a time,\"\n",
    "        startTokensIds = sp.EncodeAsIds(startPhrase)[:input_tokens_amount]     # [int, ..., tokens_length] \n",
    "        startTokensTensor = torch.tensor(startTokensIds, dtype=torch.long, device = device).unsqueeze(0)   # [1 x int, ..., tokens_length] \n",
    "        finalStoryTokensIds = startTokensIds\n",
    "    \n",
    "        for i in range(maxNewTokens):\n",
    "            lastTokensInSentence = startTokensTensor[:, -input_tokens_amount:]\n",
    "            genLogits = model(lastTokensInSentence)                         # Size: [Batch Size x Tokens Amount x Vocab Size]\n",
    "    \n",
    "            # Let's focus only on last token in sequence\n",
    "            genLogits = genLogits[:, -1, :]                                 # Size: [Batch Size x Vocab Size]  \n",
    "            probabilities = F.softmax(genLogits, dim=-1)                    # Size: [Batch Size x Vocab Size], Probavilities of each word from vocab\n",
    "            nextIdx = torch.multinomial(probabilities, num_samples = 1)     # Size: [Batch Size x 1]\n",
    "    \n",
    "            # apply running index to the running sequence \n",
    "            startTokensTensor = torch.cat((startTokensTensor, nextIdx), dim=1) # Size: [Batch Size x (Tokens Amount + 1)]\n",
    "            finalStoryTokensIds.append(nextIdx.item())\n",
    "            \n",
    "            finalStoryTokens = []\n",
    "            for tokenId in finalStoryTokensIds:\n",
    "                finalStoryTokens.append(sp.IdToPiece(tokenId))\n",
    "            \n",
    "        finalStory = ''.join(finalStoryTokens).replace('▁', ' ').strip()  # Assuming '▁' is the SentencePiece underline character\n",
    "        print(\"finalStory #\", J, \": \", finalStory, \"\\n\\n\")\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
