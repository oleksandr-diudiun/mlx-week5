{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: pyarrow in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (15.0.2)\n",
      "Requirement already satisfied: numpy<2,>=1.16.6 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from pyarrow) (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: Pillow in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (10.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from matplotlib) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: scikit-learn in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from scikit-learn) (3.4.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: torch in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from torch) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tqdm in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (4.66.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: ipdb in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (0.13.13)\n",
      "Requirement already satisfied: ipython>=7.31.1 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from ipdb) (8.23.0)\n",
      "Requirement already satisfied: decorator in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from ipdb) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from ipython>=7.31.1->ipdb) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from ipython>=7.31.1->ipdb) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from ipython>=7.31.1->ipdb) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from ipython>=7.31.1->ipdb) (2.17.2)\n",
      "Requirement already satisfied: stack-data in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from ipython>=7.31.1->ipdb) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from ipython>=7.31.1->ipdb) (5.14.2)\n",
      "Requirement already satisfied: typing-extensions in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from ipython>=7.31.1->ipdb) (4.10.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from ipython>=7.31.1->ipdb) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from jedi>=0.16->ipython>=7.31.1->ipdb) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from pexpect>4.3->ipython>=7.31.1->ipdb) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.31.1->ipdb) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from stack-data->ipython>=7.31.1->ipdb) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from stack-data->ipython>=7.31.1->ipdb) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from stack-data->ipython>=7.31.1->ipdb) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (from asttokens>=2.1.0->stack-data->ipython>=7.31.1->ipdb) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /Users/sid/workspace/mlx-week5/sid/.venv/lib/python3.11/site-packages (0.2.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install pyarrow\n",
    "\n",
    "!pip install Pillow\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn\n",
    "!pip install torch\n",
    "!pip install tqdm\n",
    "!pip install ipdb\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sid/workspace/mlx-week5/sid/notebooks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/sid/workspace/mlx-week5/train')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "\n",
    "# os.chdir(\"/root/workspace/mlx44\")\n",
    "print(os.getcwd())\n",
    "# root_path = Path(os.getcwd()).resolve().parents[0]\n",
    "# print(root_path)\n",
    "# os.chdir(\"/root/workspace/mlx44/src\")\n",
    "# os.mkdir(root_path / \"workspace/mlx44\")\n",
    "root = Path(\"/Users/sid/workspace/mlx-week5\")\n",
    "train_data_path = root / \"train\"\n",
    "train_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import itertools as its\n",
    "from tqdm import tqdm\n",
    "import ipdb\n",
    "from collections import namedtuple\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to check is mps is available on my M1 MAC?\n",
    "torch.backends.mps.is_available()\n",
    "device = torch.device(\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    "    #     else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    ")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data from a single parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a parquet file into a pandas dataframe\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "first_file = pd.read_parquet(train_data_path / \"0000.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\\n\\nLily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\"\\n\\nTogether, they shared the needle and sewed the button on Lily\\'s shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.',\n",
       " 'Once upon a time, there was a little car named Beep. Beep loved to go fast and play in the sun. Beep was a healthy car because he always had good fuel. Good fuel made Beep happy and strong.\\n\\nOne day, Beep was driving in the park when he saw a big tree. The tree had many leaves that were falling. Beep liked how the leaves fall and wanted to play with them. Beep drove under the tree and watched the leaves fall on him. He laughed and beeped his horn.\\n\\nBeep played with the falling leaves all day. When it was time to go home, Beep knew he needed more fuel. He went to the fuel place and got more healthy fuel. Now, Beep was ready to go fast and play again the next day. And Beep lived happily ever after.',\n",
       " 'One day, a little fish named Fin was swimming near the shore. He saw a big crab and wanted to be friends. \"Hi, I am Fin. Do you want to play?\" asked the little fish. The crab looked at Fin and said, \"No, I don\\'t want to play. I am cold and I don\\'t feel fine.\"\\n\\nFin felt sad but wanted to help the crab feel better. He swam away and thought of a plan. He remembered that the sun could make things warm. So, Fin swam to the top of the water and called to the sun, \"Please, sun, help my new friend feel fine and not freeze!\"\\n\\nThe sun heard Fin\\'s call and shone its warm light on the shore. The crab started to feel better and not so cold. He saw Fin and said, \"Thank you, little fish, for making me feel fine. I don\\'t feel like I will freeze now. Let\\'s play together!\" And so, Fin and the crab played and became good friends.',\n",
       " 'Once upon a time, in a land full of trees, there was a little cherry tree. The cherry tree was very sad because it did not have any friends. All the other trees were big and strong, but the cherry tree was small and weak. The cherry tree was envious of the big trees.\\n\\nOne day, the cherry tree felt a tickle in its branches. It was a little spring wind. The wind told the cherry tree not to be sad. The wind said, \"You are special because you have sweet cherries that everyone loves.\" The cherry tree started to feel a little better.\\n\\nAs time went on, the cherry tree grew more and more cherries. All the animals in the land came to eat the cherries and play under the cherry tree. The cherry tree was happy because it had many friends now. The cherry tree learned that being different can be a good thing. And they all lived happily ever after.',\n",
       " 'Once upon a time, there was a little girl named Lily. Lily liked to pretend she was a popular princess. She lived in a big castle with her best friends, a cat and a dog.\\n\\nOne day, while playing in the castle, Lily found a big cobweb. The cobweb was in the way of her fun game. She wanted to get rid of it, but she was scared of the spider that lived there.\\n\\nLily asked her friends, the cat and the dog, to help her. They all worked together to clean the cobweb. The spider was sad, but it found a new home outside. Lily, the cat, and the dog were happy they could play without the cobweb in the way. And they all lived happily ever after.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sentences = first_file[\"text\"].values\n",
    "all_sentences = all_sentences.tolist()\n",
    "all_sentences[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529930"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use sentence piece to tokenize the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets tokenize using sentence piece\n",
    "from sentencepiece import SentencePieceTrainer, SentencePieceProcessor\n",
    "import io\n",
    "\n",
    "VOCAB_SIZE = 10000\n",
    "SOS = \"<SOS>\"\n",
    "EOS = \"<EOS>\"\n",
    "\n",
    "\n",
    "# for article in articles[0:100]:\n",
    "def get_data():\n",
    "    for i in range(100):\n",
    "        file = pd.read_parquet(\n",
    "            train_data_path / f\"{str(i).zfill(4)}.parquet\", engine=\"pyarrow\"\n",
    "        )\n",
    "        for sentence in file[\"text\"].values:\n",
    "            yield sentence\n",
    "\n",
    "\n",
    "def get_model(train=False):\n",
    "    model = io.BytesIO()\n",
    "    model_filename = root / \"models/tiny_stories_tokenizer.model\"\n",
    "    if train:\n",
    "        SentencePieceTrainer.train(\n",
    "            sentence_iterator=iter(all_sentences),\n",
    "            model_writer=model,\n",
    "            vocab_size=VOCAB_SIZE,\n",
    "            user_defined_symbols=[SOS, EOS],\n",
    "            # max_sentence_length=4196,\n",
    "            # model_type=\"BPE\",\n",
    "        )\n",
    "        sp_processor = SentencePieceProcessor(model_proto=model.getvalue())\n",
    "    else:\n",
    "        sp_processor = SentencePieceProcessor(model_file=str(model_filename))\n",
    "    return sp_processor, model\n",
    "\n",
    "\n",
    "def save_model(model):\n",
    "    model_filename = root / \"models/tiny_stories_tokenizer.model\"\n",
    "    with open(model_filename, \"wb\") as f:\n",
    "        f.write(model.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_processor, model = get_model(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXECUTE ONCE WHEN YOU HAVE IT MADE\n",
    "# save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was a little girl with dark hair. Her name was Joy. She lived in a big house with her parents. One day, Joy was playing outside in her garden. Suddenly, she felt something on her leg - something pinching her. It was a big, black bug! \n",
      "\n",
      "Joy screamed and tried to get away, but the bug kept following her. She tried to run and hide, but it was too quick. \n",
      "\n",
      "Joy's parents heard her cries and came running. They used a stick to help her get rid of the bug. After the bug was gone, they hugged Joy and told her everything would be alright. \n",
      "\n",
      "When the bug was gone, Joy felt relieved and happy. She went back to playing in the garden, making sure she didn't step on any more bugs.\n",
      ".\n",
      "▁part . TMs ▁happy ▁kind ▁There ! R ▁gentle ▁sad ▁treat .\" ▁of ▁everything s ▁got ▁He When ▁girl ▁things ▁smiled ▁day ▁rid ▁decided ▁After ▁relieved ▁said ▁didn ▁named ▁told ▁because ▁like ▁taught ▁lesson ▁respect ▁fix ▁nice , ▁little ▁came ▁When ▁there ▁dark ▁too ▁shiny ▁broken ▁As ▁stick ▁searching ▁cries ▁quietly ▁who ▁up ▁boy ▁made ▁always ▁toy ▁parents ▁they ▁heard ▁making ▁She ▁for ▁outside ▁screamed ▁tried ▁following ▁knew ▁showing ▁done ▁One ▁Later ita ▁a ▁look ▁park ▁herself ▁looking ▁belonged ▁and ▁she ▁around ▁people ▁everyone ▁else ▁playing ▁run ▁sure ▁garden ▁then ▁leg ▁house ▁running ▁on ▁thanked € ▁looked ▁away ▁alright ▁small ▁surprise : ▁Once ▁very You ▁noticed ▁But ▁sweet ▁\" ▁put ▁step ▁something ▁kept ▁Joy ▁muscle ▁hair ▁are ▁someone ▁do ▁others ▁They ▁found ▁with ▁all ▁bug ▁me ▁used ▁work ▁get ▁at ▁ ▁pinching ▁picked ▁black ▁find ▁hide ▁quick ▁take ▁Her ▁the ▁feeling ▁good ▁- ▁name ▁gave ▁upon ▁walking ▁belongings ▁was ▁her ▁into ' â ▁gone ▁be ▁that ▁any !\" ▁important ▁kindness ▁managed ▁it ▁in ▁more ▁magical ▁stolen ▁Finally ▁young ▁hugged ▁had ▁to ▁time ▁were ▁went ▁but ▁back ▁would ▁realized ▁big ▁Suddenly ▁felt ▁proud ▁difference ▁help ▁thought ▁you ▁closer ▁anyone ▁It t ▁bugs ▁lived ▁can\n",
      "..\n",
      "[['▁There', '▁was', '▁a', '▁little', '▁girl', '▁with', '▁dark', '▁hair', '.', '▁Her', '▁name', '▁was', '▁Joy', '.', '▁She', '▁lived', '▁in', '▁a', '▁big', '▁house', '▁with', '▁her', '▁parents', '.', '▁One', '▁day', ',', '▁Joy', '▁was', '▁playing', '▁outside', '▁in', '▁her', '▁garden', '.', '▁Suddenly', ',', '▁she', '▁felt', '▁something', '▁on', '▁her', '▁leg', '▁-', '▁something', '▁pinching', '▁her', '.', '▁It', '▁was', '▁a', '▁big', ',', '▁black', '▁bug', '!', '▁Joy', '▁screamed', '▁and', '▁tried', '▁to', '▁get', '▁away', ',', '▁but', '▁the', '▁bug', '▁kept', '▁following', '▁her', '.', '▁She', '▁tried', '▁to', '▁run', '▁and', '▁hide', ',', '▁but', '▁it', '▁was', '▁too', '▁quick', '.', '▁Joy', \"'\", 's', '▁parents', '▁heard', '▁her', '▁cries', '▁and', '▁came', '▁running', '.', '▁They', '▁used', '▁a', '▁stick', '▁to', '▁help', '▁her', '▁get', '▁rid', '▁of', '▁the', '▁bug', '.', '▁After', '▁the', '▁bug', '▁was', '▁gone', ',', '▁they', '▁hugged', '▁Joy', '▁and', '▁told', '▁her', '▁everything', '▁would', '▁be', '▁alright', '.', '▁When', '▁the', '▁bug', '▁was', '▁gone', ',', '▁Joy', '▁felt', '▁relieved', '▁and', '▁happy', '.', '▁She', '▁went', '▁back', '▁to', '▁playing', '▁in', '▁the', '▁garden', ',', '▁making', '▁sure', '▁she', '▁didn', \"'\", 't', '▁step', '▁on', '▁any', '▁more', '▁bugs', '.'], ['▁Once', '▁upon', '▁a', '▁time', '▁there', '▁was', '▁a', '▁little', '▁girl', '▁named', '▁', 'R', 'ita', '.', '▁She', '▁was', '▁gentle', '▁and', '▁sweet', '▁and', '▁was', '▁always', '▁nice', '▁to', '▁everyone', '.', '▁One', '▁day', '▁', 'R', 'ita', '▁was', '▁walking', '▁in', '▁the', '▁park', '▁and', '▁noticed', '▁something', '▁shiny', '.', '▁She', '▁decided', '▁to', '▁take', '▁a', '▁closer', '▁look', '.', '▁As', '▁she', '▁got', '▁closer', ',', '▁she', '▁realized', '▁that', '▁someone', '▁had', '▁stolen', '▁someone', '▁else', \"'\", 's', '▁toy', '.', '▁', 'R', 'ita', '▁was', '▁very', '▁sad', '▁because', '▁she', '▁knew', '▁the', '▁toy', '▁belonged', '▁to', '▁someone', '▁else', '.', '▁But', '▁then', '▁she', '▁looked', '▁at', '▁the', '▁toy', ',', '▁she', '▁noticed', '▁that', '▁part', '▁of', '▁it', '▁was', '▁broken', '.', '▁She', '▁put', '▁her', '▁small', '▁muscle', '▁into', '▁work', '▁and', '▁managed', '▁to', '▁fix', '▁it', '.', '▁', 'R', 'ita', '▁picked', '▁up', '▁the', '▁toy', '▁and', '▁decided', '▁to', '▁find', '▁who', '▁it', '▁belonged', '▁to', '.', '▁She', '▁went', '▁all', '▁around', '▁the', '▁park', ',', '▁showing', '▁the', '▁toy', '▁to', '▁anyone', '▁who', '▁looked', '▁like', '▁they', '▁were', '▁searching', '▁for', '▁it', '.', '▁Finally', ',', '▁she', '▁found', '▁a', '▁young', '▁boy', '▁who', '▁was', '▁looking', '▁for', '▁the', '▁toy', '.', '▁', 'R', 'ita', '▁quietly', '▁gave', '▁the', '▁toy', '▁to', '▁the', '▁boy', ',', '▁who', '▁looked', '▁at', '▁her', '▁in', '▁surprise', '.', '▁He', '▁thanked', '▁her', '▁and', '▁said', ',', '▁\"', 'You', '▁taught', '▁me', '▁a', '▁very', '▁important', '▁lesson', ':', '▁to', '▁respect', '▁people', 'â', '€', 'TMs', '▁belongings', '▁and', '▁to', '▁treat', '▁others', '▁with', '▁kindness', '.\"', '▁', 'R', 'ita', '▁smiled', ',', '▁feeling', '▁proud', '▁of', '▁herself', '.', '▁She', '▁had', '▁done', '▁something', '▁good', '▁and', '▁made', '▁a', '▁difference', '.', '▁Later', '▁that', '▁day', ',', '▁', 'R', 'ita', '▁thought', '▁to', '▁herself', ',', '▁\"', 'When', '▁you', '▁are', '▁gentle', '▁and', '▁kind', ',', '▁you', '▁can', '▁do', '▁magical', '▁things', '!\"']]\n",
      "...\n",
      "[[526, 11, 10, 40, 61, 24, 507, 587, 5, 174, 450, 11, 2821, 5, 14, 254, 22, 10, 48, 179, 24, 15, 464, 5, 53, 28, 8, 2821, 11, 127, 161, 22, 15, 225, 5, 202, 8, 25, 87, 111, 35, 15, 1275, 490, 111, 5795, 15, 5, 43, 11, 10, 48, 8, 772, 723, 38, 2821, 985, 6, 184, 9, 150, 105, 8, 55, 7, 723, 272, 2746, 15, 5, 14, 184, 9, 285, 6, 638, 8, 55, 12, 11, 80, 2233, 5, 2821, 18, 23, 464, 191, 15, 1233, 6, 137, 483, 5, 17, 457, 10, 549, 9, 97, 15, 150, 3664, 30, 7, 723, 5, 274, 7, 723, 11, 553, 8, 33, 206, 2821, 6, 188, 15, 630, 100, 68, 2799, 5, 170, 7, 723, 11, 553, 8, 2821, 87, 900, 6, 44, 5, 14, 71, 79, 9, 127, 22, 7, 225, 8, 432, 359, 25, 154, 18, 47, 1555, 35, 572, 162, 1074, 5], [58, 62, 10, 39, 41, 11, 10, 40, 61, 83, 51, 0, 5315, 5, 14, 11, 765, 6, 554, 6, 11, 156, 214, 9, 341, 5, 53, 28, 51, 0, 5315, 11, 304, 22, 7, 113, 6, 329, 111, 280, 5, 14, 136, 9, 166, 10, 362, 183, 5, 252, 25, 133, 362, 8, 25, 413, 29, 563, 32, 4029, 563, 538, 18, 23, 173, 5, 51, 0, 5315, 11, 37, 117, 211, 25, 169, 7, 173, 1496, 9, 563, 538, 5, 75, 123, 25, 89, 76, 7, 173, 8, 25, 329, 29, 1065, 30, 12, 11, 547, 5, 14, 118, 15, 219, 4471, 185, 364, 6, 1453, 9, 616, 12, 5, 51, 0, 5315, 302, 69, 7, 173, 6, 136, 9, 148, 129, 12, 1496, 9, 5, 14, 71, 78, 91, 7, 113, 8, 1626, 7, 173, 9, 950, 129, 89, 85, 33, 56, 1756, 36, 12, 5, 527, 8, 25, 124, 10, 821, 93, 129, 11, 316, 36, 7, 173, 5, 51, 0, 5315, 2566, 189, 7, 173, 9, 7, 93, 8, 129, 89, 76, 15, 22, 471, 5, 16, 227, 15, 6, 20, 8, 13, 253, 1209, 151, 10, 37, 335, 476, 0, 9, 1352, 259, 94, 95, 508, 5056, 6, 9, 931, 625, 24, 1467, 50, 51, 0, 5315, 82, 8, 300, 204, 30, 535, 5, 14, 32, 437, 111, 158, 6, 110, 10, 2980, 5, 873, 29, 28, 8, 51, 0, 5315, 165, 9, 535, 8, 13, 4073, 31, 59, 765, 6, 243, 8, 31, 74, 115, 701, 130, 54]]\n"
     ]
    }
   ],
   "source": [
    "print(all_sentences[100])\n",
    "print(\".\")\n",
    "print(\n",
    "    \" \".join(\n",
    "        list(\n",
    "            set(\n",
    "                [\n",
    "                    w\n",
    "                    for lst in sp_processor.encode_as_pieces(all_sentences[100:102])\n",
    "                    for w in lst\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "print(\"..\")\n",
    "print(sp_processor.encode_as_pieces(all_sentences[100:102]))\n",
    "print(\"...\")\n",
    "print(sp_processor.encode_as_ids(all_sentences[100:102]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', '<SOS>', 'There', '▁was', '▁a', '▁little', '▁girl', '▁with', '▁dark', '▁hair', '.', '▁Her', '▁name', '▁was', '▁Joy', '.', '▁She', '▁lived', '▁in', '▁a', '▁big', '▁house', '▁with', '▁her', '▁parents', '.', '▁One', '▁day', ',', '▁Joy', '▁was', '▁playing', '▁outside', '▁in', '▁her', '▁garden', '.', '▁Suddenly', ',', '▁she', '▁felt', '▁something', '▁on', '▁her', '▁leg', '▁-', '▁something', '▁pinching', '▁her', '.', '▁It', '▁was', '▁a', '▁big', ',', '▁black', '▁bug', '!', '▁Joy', '▁screamed', '▁and', '▁tried', '▁to', '▁get', '▁away', ',', '▁but', '▁the', '▁bug', '▁kept', '▁following', '▁her', '.', '▁She', '▁tried', '▁to', '▁run', '▁and', '▁hide', ',', '▁but', '▁it', '▁was', '▁too', '▁quick', '.', '▁Joy', \"'\", 's', '▁parents', '▁heard', '▁her', '▁cries', '▁and', '▁came', '▁running', '.', '▁They', '▁used', '▁a', '▁stick', '▁to', '▁help', '▁her', '▁get', '▁rid', '▁of', '▁the', '▁bug', '.', '▁After', '▁the', '▁bug', '▁was', '▁gone', ',', '▁they', '▁hugged', '▁Joy', '▁and', '▁told', '▁her', '▁everything', '▁would', '▁be', '▁alright', '.', '▁When', '▁the', '▁bug', '▁was', '▁gone', ',', '▁Joy', '▁felt', '▁relieved', '▁and', '▁happy', '.', '▁She', '▁went', '▁back', '▁to', '▁playing', '▁in', '▁the', '▁garden', ',', '▁making', '▁sure', '▁she', '▁didn', \"'\", 't', '▁step', '▁on', '▁any', '▁more', '▁bugs', '.', '<EOS>']\n",
      "['▁', '<SOS>', 'Once', '▁upon', '▁a', '▁time', '▁there', '▁was', '▁a', '▁little', '▁girl', '▁named', '▁', 'R', 'ita', '.', '▁She', '▁was', '▁gentle', '▁and', '▁sweet', '▁and', '▁was', '▁always', '▁nice', '▁to', '▁everyone', '.', '▁One', '▁day', '▁', 'R', 'ita', '▁was', '▁walking', '▁in', '▁the', '▁park', '▁and', '▁noticed', '▁something', '▁shiny', '.', '▁She', '▁decided', '▁to', '▁take', '▁a', '▁closer', '▁look', '.', '▁As', '▁she', '▁got', '▁closer', ',', '▁she', '▁realized', '▁that', '▁someone', '▁had', '▁stolen', '▁someone', '▁else', \"'\", 's', '▁toy', '.', '▁', 'R', 'ita', '▁was', '▁very', '▁sad', '▁because', '▁she', '▁knew', '▁the', '▁toy', '▁belonged', '▁to', '▁someone', '▁else', '.', '▁But', '▁then', '▁she', '▁looked', '▁at', '▁the', '▁toy', ',', '▁she', '▁noticed', '▁that', '▁part', '▁of', '▁it', '▁was', '▁broken', '.', '▁She', '▁put', '▁her', '▁small', '▁muscle', '▁into', '▁work', '▁and', '▁managed', '▁to', '▁fix', '▁it', '.', '▁', 'R', 'ita', '▁picked', '▁up', '▁the', '▁toy', '▁and', '▁decided', '▁to', '▁find', '▁who', '▁it', '▁belonged', '▁to', '.', '▁She', '▁went', '▁all', '▁around', '▁the', '▁park', ',', '▁showing', '▁the', '▁toy', '▁to', '▁anyone', '▁who', '▁looked', '▁like', '▁they', '▁were', '▁searching', '▁for', '▁it', '.', '▁Finally', ',', '▁she', '▁found', '▁a', '▁young', '▁boy', '▁who', '▁was', '▁looking', '▁for', '▁the', '▁toy', '.', '▁', 'R', 'ita', '▁quietly', '▁gave', '▁the', '▁toy', '▁to', '▁the', '▁boy', ',', '▁who', '▁looked', '▁at', '▁her', '▁in', '▁surprise', '.', '▁He', '▁thanked', '▁her', '▁and', '▁said', ',', '▁\"', 'You', '▁taught', '▁me', '▁a', '▁very', '▁important', '▁lesson', ':', '▁to', '▁respect', '▁people', 'â', '€', 'TMs', '▁belongings', '▁and', '▁to', '▁treat', '▁others', '▁with', '▁kindness', '.\"', '▁', 'R', 'ita', '▁smiled', ',', '▁feeling', '▁proud', '▁of', '▁herself', '.', '▁She', '▁had', '▁done', '▁something', '▁good', '▁and', '▁made', '▁a', '▁difference', '.', '▁Later', '▁that', '▁day', ',', '▁', 'R', 'ita', '▁thought', '▁to', '▁herself', ',', '▁\"', 'When', '▁you', '▁are', '▁gentle', '▁and', '▁kind', ',', '▁you', '▁can', '▁do', '▁magical', '▁things', '!\"', '<EOS>']\n",
      "['▁', '<SOS>', 'One', '▁day', ',', '▁John', '▁and', '▁his', '▁mom', '▁were', '▁out', '▁in', '▁the', '▁woods', '.', '▁John', '▁was', '▁looking', '▁to', '▁find', '▁some', '▁lumber', '▁for', '▁his', '▁toy', '▁boat', '.', '▁They', '▁had', '▁been', '▁sc', 'our', 'ging', '▁for', '▁hours', ',', '▁but', '▁hadn', \"'\", 't', '▁found', '▁anything', '▁yet', '.', '▁\"', 'Are', '▁you', '▁sure', '▁there', \"'\", 's', '▁lumber', '▁around', '▁here', ',', '▁Mom', '?\"', '▁asked', '▁John', '.', '▁\"', 'Of', '▁course', ',\"', '▁she', '▁said', '▁happily', '.', '▁\"', 'Just', '▁keep', '▁looking', ',', '▁I', \"'\", 'm', '▁sure', '▁we', \"'\", 'll', '▁find', '▁it', '.\"', '▁John', '▁kept', '▁searching', ',', '▁but', '▁soon', '▁stumbled', '▁upon', '▁an', '▁ancient', '▁chest', '.', '▁He', '▁excitedly', '▁opened', '▁it', ',', '▁de', 'mon', 's', 't', 'ra', 'ting', '▁his', '▁dependable', '▁strength', '.', '▁Inside', ',', '▁he', '▁found', '▁the', '▁lumber', '▁he', '▁was', '▁looking', '▁for', '.', '▁John', '▁quickly', '▁improved', '▁his', '▁toy', '▁boat', ',', '▁since', '▁his', '▁strength', '▁was', '▁now', '▁dependable', '.', '▁With', '▁newfound', '▁confidence', ',', '▁John', '▁raced', '▁off', '▁with', '▁his', '▁boat', '▁in', '▁the', '▁river', '.', '▁He', '▁sailed', '▁faster', '▁than', '▁ever', ',', '▁enjoying', '▁the', '▁adventure', '▁he', '▁had', '▁found', '.', '▁John', '▁sure', '▁was', '▁glad', '▁he', '▁found', '▁that', '▁lumber', '!', '<EOS>']\n",
      "['▁', '<SOS>', 'Once', '▁upon', '▁a', '▁time', ',', '▁there', '▁was', '▁a', '▁little', '▁boy', '▁named', '▁Thomas', '.', '▁He', '▁was', '▁three', '▁years', '▁old', '▁and', '▁loved', '▁to', '▁explore', '.', '▁One', '▁day', ',', '▁he', '▁went', '▁on', '▁a', '▁big', '▁adventure', '▁to', '▁a', '▁far', '▁away', '▁oasis', '.', '▁On', '▁his', '▁way', ',', '▁he', '▁found', '▁a', '▁broken', '▁tree', '▁branch', '.', '▁He', '▁decided', '▁to', '▁touch', '▁it', ',', '▁but', '▁quickly', '▁pulled', '▁his', '▁hand', '▁away', '▁as', '▁it', '▁was', '▁too', '▁sharp', '.', '▁As', '▁Thomas', '▁continued', '▁his', '▁journey', ',', '▁he', '▁pond', 'ered', '▁why', '▁the', '▁branch', '▁was', '▁so', '▁broken', '.', '▁He', '▁soon', '▁came', '▁across', '▁a', '▁little', '▁river', '▁that', '▁was', '▁flowing', '▁down', '▁the', '▁side', '▁of', '▁the', '▁oasis', '.', '▁He', '▁remembered', '▁the', '▁branch', '▁and', '▁wondered', '▁if', '▁the', '▁river', '▁had', '▁something', '▁to', '▁do', '▁with', '▁it', '.', '▁The', '▁little', '▁boy', '▁arrived', '▁at', '▁the', '▁oasis', '▁and', '▁he', '▁was', '▁in', '▁awe', '.', '▁He', '▁ran', '▁to', '▁the', '▁edge', '▁of', '▁the', '▁water', '▁and', '▁started', '▁to', '▁touch', '▁it', '.', '▁As', '▁soon', '▁as', '▁he', '▁did', ',', '▁the', '▁river', '▁started', '▁to', '▁swell', '▁and', '▁the', '▁current', '▁quickly', '▁became', '▁stronger', '.', '▁Thomas', '▁quickly', '▁pulled', '▁his', '▁hand', '▁away', '.', '▁The', '▁little', '▁boy', '▁realized', '▁that', '▁the', '▁branch', '▁had', '▁broken', '▁from', '▁the', '▁', 'ra', 'pi', 'd', 'ly', '▁rising', '▁water', 's', '.', '▁Thomas', '▁now', '▁understood', '▁why', '▁the', '▁branch', '▁was', '▁so', '▁broken', '▁and', '▁he', '▁was', '▁careful', '▁not', '▁to', '▁touch', '▁it', '▁again', '.', '<EOS>']\n",
      "['▁', '<SOS>', 'Once', '▁upon', '▁a', '▁time', ',', '▁there', '▁was', '▁a', '▁lazy', '▁figure', '▁who', '▁was', '▁always', '▁looking', '▁for', '▁ways', '▁to', '▁relax', '.', '▁One', '▁day', ',', '▁he', '▁saw', '▁a', '▁big', '▁tree', '▁in', '▁the', '▁distance', '▁and', '▁decided', '▁to', '▁take', '▁a', '▁nap', '.', '▁As', '▁he', '▁was', '▁lying', '▁there', ',', '▁a', '▁small', '▁voice', '▁shouted', ',', '▁', 'â', '€', 'œHey', '!', '▁Wake', '▁up', '!', 'â', '€', '▁The', '▁lazy', '▁figure', '▁opened', '▁his', '▁eyes', '▁and', '▁saw', '▁a', '▁small', '▁child', '▁standing', '▁in', '▁front', '▁of', '▁him', '.', '▁The', '▁child', '▁was', '▁insisting', '▁that', '▁the', '▁figure', '▁should', '▁come', '▁play', '▁with', '▁him', '.', '▁But', '▁the', '▁lazy', '▁figure', '▁was', '▁feeling', '▁too', '▁lazy', '▁to', '▁move', '▁so', '▁he', '▁politely', '▁dec', 'lined', '▁the', '▁friendly', '▁offer', '.', '▁The', '▁child', '▁was', '▁very', '▁persistent', ',', '▁though', ',', '▁and', '▁he', '▁kept', '▁insisting', '▁that', '▁the', '▁figure', '▁should', '▁come', '▁play', '.', '▁So', '▁the', '▁figure', '▁finally', '▁gave', '▁in', '▁and', '▁agreed', '▁to', '▁follow', '▁the', '▁child', \"'\", 's', '▁lead', '.', '▁And', '▁so', ',', '▁the', '▁lazy', '▁figure', '▁followed', '▁the', '▁boy', '▁and', '▁had', '▁the', '▁most', '▁amazing', '▁day', '!', '▁They', '▁laughed', '▁and', '▁played', '▁for', '▁hours', '▁and', '▁soon', '▁their', '▁day', '▁had', '▁come', '▁to', '▁an', '▁end', '.', '▁The', '▁figure', '▁was', '▁very', '▁grateful', '▁for', '▁the', '▁company', '▁and', '▁said', '▁goodbye', '▁to', '▁the', '▁wonderful', '▁little', '▁child', '.', '▁The', '▁figure', '▁returned', '▁home', '▁feeling', '▁refreshed', '▁and', '▁kids', '▁all', '▁around', '▁continued', '▁to', '▁insist', '▁that', '▁he', '▁join', '▁them', '▁to', '▁have', '▁lots', '▁of', '▁fun', '.', '▁The', '▁end', '.', '<EOS>']\n",
      "['▁', '<SOS>', 'Once', '▁upon', '▁a', '▁time', '▁there', '▁was', '▁a', '▁new', '▁little', '▁bunny', '.', '▁Her', '▁name', '▁was', '▁Chloe', '▁and', '▁she', '▁was', '▁very', '▁excited', '▁to', '▁explore', '▁the', '▁world', '.', '▁One', '▁day', '▁she', '▁was', '▁hopping', '▁in', '▁the', '▁forest', '▁when', '▁something', '▁big', '▁happened', '!', '▁The', '▁trees', '▁began', '▁to', '▁shake', '▁and', '▁the', '▁ground', '▁rumbled', '.', '▁Chloe', '▁didn', \"'\", 't', '▁know', '▁what', '▁to', '▁do', ',', '▁so', '▁she', '▁crouch', 'ed', '▁down', '▁and', '▁covered', '▁her', '▁ears', '▁until', '▁the', '▁shaking', '▁stopped', '.', '▁When', '▁it', '▁was', '▁all', '▁over', ',', '▁Chloe', '▁looked', '▁around', '▁and', '▁saw', '▁all', '▁of', '▁the', '▁other', '▁animals', '.', '▁They', '▁were', '▁all', '▁looking', '▁just', '▁as', '▁scared', '▁as', '▁she', '▁felt', '.', '▁Suddenly', ',', '▁a', '▁wise', '▁old', '▁owl', '▁spoke', '▁up', '.', '▁\"', 'My', '▁friends', ',\"', '▁he', '▁said', '.', '▁\"', 'We', '▁just', '▁had', '▁an', '▁earthquake', '!\"', '▁Everyone', '▁looked', '▁confused', '.', '▁\"', 'What', '▁is', '▁an', '▁earthquake', '?\"', '▁Chloe', '▁asked', '.', '▁\"', 'It', '▁is', '▁a', '▁big', '▁shaking', '▁that', '▁happens', '▁sometimes', ',\"', '▁said', '▁the', '▁owl', '.', '▁\"', 'We', '▁all', '▁need', '▁to', '▁be', '▁careful', '▁when', '▁it', '▁happens', '!\"', '▁Chloe', '▁thanked', '▁the', '▁owl', '▁for', '▁teaching', '▁her', '▁something', '▁new', '▁and', ',', '▁after', '▁that', '▁day', ',', '▁she', '▁liked', '▁to', '▁be', '▁extra', '▁careful', '▁whenever', '▁she', '▁heard', '▁rumbling', '▁in', '▁the', '▁ground', '.', '<EOS>']\n",
      "['▁', '<SOS>', 'Once', '▁upon', '▁a', '▁time', ',', '▁there', '▁was', '▁a', '▁little', '▁girl', '▁named', '▁Molly', '.', '▁She', '▁was', '▁very', '▁worried', ',', '▁because', '▁she', '▁had', '▁lost', '▁her', '▁favorite', '▁toy', '.', '▁One', '▁night', ',', '▁while', '▁she', '▁was', '▁crying', '▁in', '▁bed', ',', '▁she', '▁heard', '▁a', '▁gentle', '▁hoot', 'ing', '▁sound', '.', '▁Molly', '▁opened', '▁her', '▁window', '▁and', '▁a', '▁friendly', '▁owl', '▁flew', '▁in', '.', '▁Molly', '▁was', '▁surprised', ',', '▁but', '▁the', '▁owl', '▁only', '▁wanted', '▁to', '▁help', '.', '▁It', '▁flew', '▁around', '▁the', '▁room', ',', '▁searching', '▁until', '▁it', '▁found', '▁Molly', \"'\", 's', '▁toy', '.', '▁It', '▁bowed', '▁its', '▁wings', '▁and', '▁dropped', '▁the', '▁toy', '▁in', '▁Molly', \"'\", 's', '▁lap', '.', '▁Molly', '▁was', '▁amazed', '▁and', '▁asked', '▁the', '▁owl', ',', '▁', 'â', '€', 'œWhat', '▁are', '▁you', '?', 'â', '€', '▁The', '▁owl', '▁hooted', '▁again', '▁and', '▁said', ',', '▁', 'â', '€', 'œI', \"'\", 'm', '▁an', '▁owl', '!', '▁I', '▁saw', '▁that', '▁you', '▁were', '▁worried', '▁so', '▁I', '▁wanted', '▁to', '▁come', '▁and', '▁restore', '▁your', '▁toy', '.', '▁Now', ',', '▁please', '▁have', '▁a', '▁good', '▁night', \"'\", 's', '▁sleep', '.', 'â', '€', '▁Molly', '▁thanked', '▁the', '▁owl', '▁and', '▁fell', '▁asleep', '▁with', '▁a', '▁smile', '▁on', '▁her', '▁face', '.', '▁From', '▁that', '▁day', '▁on', ',', '▁Molly', '▁was', '▁sure', '▁that', '▁owl', 's', '▁were', '▁magical', '▁creatures', '▁who', '▁could', '▁make', '▁any', '▁worries', '▁go', '▁away', '.', '<EOS>']\n",
      "['▁', '<SOS>', 'Once', '▁upon', '▁a', '▁time', '▁there', '▁was', '▁a', '▁small', '▁boy', '▁who', '▁wanted', '▁to', '▁go', '▁on', '▁an', '▁adventure', '.', '▁He', '▁decided', '▁to', '▁take', '▁a', '▁boat', '▁out', '▁to', '▁sea', '.', '▁After', '▁a', '▁few', '▁hours', ',', '▁the', '▁boat', '▁sailed', '▁onto', '▁a', '▁big', ',', '▁beautiful', '▁island', '.', '▁The', '▁island', '▁was', '▁so', '▁nice', '▁that', '▁the', '▁boy', '▁wanted', '▁to', '▁explore', '▁it', '.', '▁He', '▁jumped', '▁out', '▁of', '▁the', '▁boat', '▁into', '▁the', '▁water', '▁and', '▁started', '▁to', '▁swim', '▁towards', '▁the', '▁island', '.', '▁There', '▁was', '▁a', '▁mild', '▁breeze', '▁that', '▁kept', '▁him', '▁cool', '▁as', '▁he', '▁swam', '.', '▁The', '▁boy', '▁arrived', '▁on', '▁the', '▁shore', '▁of', '▁the', '▁island', '.', '▁He', '▁looked', '▁around', '▁and', '▁noticed', '▁a', '▁small', '▁hut', '.', '▁He', '▁stood', '▁up', '▁and', '▁walked', '▁towards', '▁it', '.', '▁When', '▁he', '▁arrived', ',', '▁he', '▁heard', '▁a', '▁voice', '▁say', ',', '▁\"', 'Hello', '!', '▁Who', '▁are', '▁you', '?\"', '▁The', '▁boy', '▁was', '▁surprised', '.', '▁He', '▁looked', '▁around', '▁and', '▁saw', '▁an', '▁old', '▁man', '▁standing', '▁nearby', '.', '▁The', '▁old', '▁man', '▁said', ',', '▁\"', 'I', \"'\", 'm', '▁the', '▁island', \"'\", 's', '▁caretaker', '.', '▁My', '▁name', '▁is', '▁John', '.', '▁What', \"'\", 's', '▁your', '▁name', '?\"', '▁The', '▁boy', '▁smiled', '▁and', '▁said', '▁his', '▁name', '.', '▁Then', '▁he', '▁asked', '▁if', '▁he', '▁could', '▁explore', '▁the', '▁island', '.', '▁John', '▁said', '▁to', '▁him', ',', '▁\"', 'Of', '▁course', '▁you', '▁can', '.', '▁Just', '▁be', '▁careful', '▁-', '▁some', '▁of', '▁the', '▁island', '▁can', '▁be', '▁a', '▁bit', '▁wild', '.', '▁I', \"'\", 'll', '▁stay', '▁here', '▁and', '▁make', '▁sure', '▁you', \"'\", 're', '▁safe', '.\"', '▁So', '▁the', '▁boy', '▁explored', '▁the', '▁island', '▁with', '▁John', '.', '▁They', '▁walked', '▁around', '▁the', '▁beach', '▁and', '▁swam', '▁in', '▁the', '▁mild', '▁ocean', '.', '▁Then', ',', '▁when', '▁it', '▁was', '▁time', '▁to', '▁go', '▁back', ',', '▁the', '▁boy', '▁thanked', '▁John', '▁for', '▁showing', '▁him', '▁the', '▁island', '▁and', '▁waved', '▁goodbye', '.', '▁The', '▁boy', '▁sailed', '▁back', '▁to', '▁the', '▁shore', '▁with', '▁lots', '▁of', '▁great', '▁memories', '▁of', '▁the', '▁island', '.', '▁He', '<EOS>']\n",
      "['▁', '<SOS>', 'Once', '▁upon', '▁a', '▁time', '▁there', '▁was', '▁a', '▁fairy', '▁who', '▁lived', '▁in', '▁a', '▁tree', '▁near', '▁a', '▁pond', '.', '▁The', '▁fairy', '▁was', '▁very', '▁stubborn', '▁and', '▁always', '▁wanted', '▁things', '▁to', '▁go', '▁her', '▁way', '.', '▁One', '▁day', '▁when', '▁the', '▁fairy', '▁was', '▁flying', '▁around', '▁the', '▁tree', ',', '▁she', '▁saw', '▁a', '▁boy', '▁who', '▁was', '▁playing', '▁by', '▁the', '▁pond', '.', '▁The', '▁boy', '▁had', '▁a', '▁red', '▁balloon', '▁which', '▁he', '▁was', '▁dropping', '▁into', '▁the', '▁pond', '.', '▁The', '▁fairy', '▁shouted', '▁to', '▁the', '▁boy', ',', '▁\"', 'stop', ',', '▁don', \"'\", 't', '▁drop', '▁the', '▁balloon', '!\"', '▁But', '▁the', '▁boy', '▁was', '▁too', '▁stubborn', '▁to', '▁listen', '▁and', '▁he', '▁dropped', '▁the', '▁balloon', '▁into', '▁the', '▁pond', '.', '▁The', '▁fairy', '▁flew', '▁down', '▁to', '▁the', '▁pond', ',', '▁and', '▁with', '▁a', '▁wave', '▁of', '▁her', '▁magic', '▁wand', ',', '▁the', '▁balloon', '▁rose', '▁up', '▁out', '▁of', '▁the', '▁pond', ',', '▁much', '▁d', 'ri', 'er', '▁and', '▁brighter', '▁than', '▁before', '.', '▁The', '▁boy', '▁was', '▁so', '▁happy', '.', '▁He', '▁hugged', '▁the', '▁fairy', '▁and', '▁thanked', '▁her', '▁for', '▁saving', '▁his', '▁balloon', '.', '▁The', '▁fairy', '▁smiled', '▁and', '▁said', ',', '▁\"', 'You', '▁must', '▁be', '▁more', '▁careful', '▁next', '▁time', '▁and', '▁listen', '▁to', '▁me', '!\"', '<EOS>']\n",
      "['▁', '<SOS>', 'Once', '▁upon', '▁a', '▁time', '▁there', '▁was', '▁a', '▁black', '▁record', '.', '▁It', '▁was', '▁very', '▁helpful', '▁and', '▁it', '▁could', '▁do', '▁great', '▁things', '.', '▁One', '▁day', ',', '▁a', '▁', '3', '▁year', '▁old', '▁wanted', '▁to', '▁use', '▁the', '▁record', '.', '▁The', '▁record', '▁said', ',', '▁\"', 'I', '▁can', \"'\", 't', '▁help', '▁you', '▁out', '.', '▁You', '▁have', '▁to', '▁be', '▁older', '\".', '▁The', '▁', '3', '▁year', '▁old', '▁was', '▁very', '▁sad', '.', '▁Then', ',', '▁an', '▁old', '▁man', '▁showed', '▁up', '.', '▁He', '▁was', '▁very', '▁helpful', '▁and', '▁offered', '▁to', '▁help', '▁find', '▁a', '▁way', '▁to', '▁make', '▁the', '▁record', '▁work', '.', '▁He', '▁tried', '▁to', '▁figure', '▁out', '▁how', '▁to', '▁make', '▁the', '▁record', '▁work', ',', '▁but', '▁no', '▁matter', '▁how', '▁hard', '▁he', '▁tried', ',', '▁he', '▁couldn', \"'\", 't', '▁make', '▁the', '▁record', '▁work', '.', '▁The', '▁', '3', '▁year', '▁old', '▁was', '▁very', '▁sad', '.', '▁He', '▁asked', '▁the', '▁old', '▁man', ',', '▁\"', 'Can', '▁you', '▁make', '▁it', '▁work', '?\"', '▁The', '▁old', '▁man', '▁shook', '▁his', '▁head', '▁and', '▁said', ',', '▁\"', 'I', \"'\", 'm', '▁sorry', ',', '▁but', '▁I', '▁can', \"'\", 't', '▁make', '▁it', '▁work', '.', '▁I', '▁tried', '▁everything', '▁I', '▁could', '.', '▁I', \"'\", 'm', '▁afraid', '▁the', '▁record', '▁will', '▁never', '▁work', '▁again', '.\"', '▁The', '▁', '3', '▁year', '▁old', '▁was', '▁very', '▁sad', '▁and', '▁never', '▁forgot', '▁the', '▁black', '▁record', '.', '▁The', '▁', '3', '▁year', '▁old', '▁never', '▁saw', '▁the', '▁old', '▁man', '▁again', '.', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "sp_processor.encode_as_pieces(\n",
    "    \"<SOS> hen the bug was gone, Joy felt relieved and happy. She went <EOS>\"\n",
    ")\n",
    "\n",
    "# sp_processor.encode_as_ids(\"<SOS>en the bug was gone, Joy felt relieved and happy. She went <EOS>\")\n",
    "for sentence in all_sentences[100:110]:\n",
    "    sentence = f\"<SOS>{sentence}<EOS>\"\n",
    "    print(sp_processor.encode_as_pieces(sentence))\n",
    "# sp_processor.encode_as_pieces(\"<SOS>hen the bug was gone, Joy felt relieved and happy. She went<EOS>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_tokens = sp_processor.encode_as_ids(all_sentences[0:10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data generation utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[526, 11, 10, 40, 61, 24, 507, 587, 5, 174, 450, 11, 2821, 5, 14, 254] [11, 10, 40, 61, 24, 507, 587, 5, 174, 450, 11, 2821, 5, 14, 254, 22]\n",
      "[11, 10, 40, 61, 24, 507, 587, 5, 174, 450, 11, 2821, 5, 14, 254, 22] [10, 40, 61, 24, 507, 587, 5, 174, 450, 11, 2821, 5, 14, 254, 22, 10]\n",
      "[10, 40, 61, 24, 507, 587, 5, 174, 450, 11, 2821, 5, 14, 254, 22, 10] [40, 61, 24, 507, 587, 5, 174, 450, 11, 2821, 5, 14, 254, 22, 10, 48]\n",
      "[40, 61, 24, 507, 587, 5, 174, 450, 11, 2821, 5, 14, 254, 22, 10, 48] [61, 24, 507, 587, 5, 174, 450, 11, 2821, 5, 14, 254, 22, 10, 48, 179]\n",
      "[61, 24, 507, 587, 5, 174, 450, 11, 2821, 5, 14, 254, 22, 10, 48, 179] [24, 507, 587, 5, 174, 450, 11, 2821, 5, 14, 254, 22, 10, 48, 179, 24]\n",
      "[24, 507, 587, 5, 174, 450, 11, 2821, 5, 14, 254, 22, 10, 48, 179, 24] [507, 587, 5, 174, 450, 11, 2821, 5, 14, 254, 22, 10, 48, 179, 24, 15]\n",
      "[507, 587, 5, 174, 450, 11, 2821, 5, 14, 254, 22, 10, 48, 179, 24, 15] [587, 5, 174, 450, 11, 2821, 5, 14, 254, 22, 10, 48, 179, 24, 15, 464]\n",
      "[587, 5, 174, 450, 11, 2821, 5, 14, 254, 22, 10, 48, 179, 24, 15, 464] [5, 174, 450, 11, 2821, 5, 14, 254, 22, 10, 48, 179, 24, 15, 464, 5]\n",
      "[5, 174, 450, 11, 2821, 5, 14, 254, 22, 10, 48, 179, 24, 15, 464, 5] [174, 450, 11, 2821, 5, 14, 254, 22, 10, 48, 179, 24, 15, 464, 5, 53]\n",
      "[174, 450, 11, 2821, 5, 14, 254, 22, 10, 48, 179, 24, 15, 464, 5, 53] [450, 11, 2821, 5, 14, 254, 22, 10, 48, 179, 24, 15, 464, 5, 53, 28]\n",
      "[450, 11, 2821, 5, 14, 254, 22, 10, 48, 179, 24, 15, 464, 5, 53, 28] [11, 2821, 5, 14, 254, 22, 10, 48, 179, 24, 15, 464, 5, 53, 28, 8]\n",
      "[11, 2821, 5, 14, 254, 22, 10, 48, 179, 24, 15, 464, 5, 53, 28, 8] [2821, 5, 14, 254, 22, 10, 48, 179, 24, 15, 464, 5, 53, 28, 8, 2821]\n",
      "[2821, 5, 14, 254, 22, 10, 48, 179, 24, 15, 464, 5, 53, 28, 8, 2821] [5, 14, 254, 22, 10, 48, 179, 24, 15, 464, 5, 53, 28, 8, 2821, 11]\n",
      "[5, 14, 254, 22, 10, 48, 179, 24, 15, 464, 5, 53, 28, 8, 2821, 11] [14, 254, 22, 10, 48, 179, 24, 15, 464, 5, 53, 28, 8, 2821, 11, 127]\n",
      "[14, 254, 22, 10, 48, 179, 24, 15, 464, 5, 53, 28, 8, 2821, 11, 127] [254, 22, 10, 48, 179, 24, 15, 464, 5, 53, 28, 8, 2821, 11, 127, 161]\n",
      "[254, 22, 10, 48, 179, 24, 15, 464, 5, 53, 28, 8, 2821, 11, 127, 161] [22, 10, 48, 179, 24, 15, 464, 5, 53, 28, 8, 2821, 11, 127, 161, 22]\n",
      "[22, 10, 48, 179, 24, 15, 464, 5, 53, 28, 8, 2821, 11, 127, 161, 22] [10, 48, 179, 24, 15, 464, 5, 53, 28, 8, 2821, 11, 127, 161, 22, 15]\n",
      "[10, 48, 179, 24, 15, 464, 5, 53, 28, 8, 2821, 11, 127, 161, 22, 15] [48, 179, 24, 15, 464, 5, 53, 28, 8, 2821, 11, 127, 161, 22, 15, 225]\n",
      "[48, 179, 24, 15, 464, 5, 53, 28, 8, 2821, 11, 127, 161, 22, 15, 225] [179, 24, 15, 464, 5, 53, 28, 8, 2821, 11, 127, 161, 22, 15, 225, 5]\n",
      "[179, 24, 15, 464, 5, 53, 28, 8, 2821, 11, 127, 161, 22, 15, 225, 5] [24, 15, 464, 5, 53, 28, 8, 2821, 11, 127, 161, 22, 15, 225, 5, 202]\n",
      "[24, 15, 464, 5, 53, 28, 8, 2821, 11, 127, 161, 22, 15, 225, 5, 202] [15, 464, 5, 53, 28, 8, 2821, 11, 127, 161, 22, 15, 225, 5, 202, 8]\n",
      "[15, 464, 5, 53, 28, 8, 2821, 11, 127, 161, 22, 15, 225, 5, 202, 8] [464, 5, 53, 28, 8, 2821, 11, 127, 161, 22, 15, 225, 5, 202, 8, 25]\n",
      "[464, 5, 53, 28, 8, 2821, 11, 127, 161, 22, 15, 225, 5, 202, 8, 25] [5, 53, 28, 8, 2821, 11, 127, 161, 22, 15, 225, 5, 202, 8, 25, 87]\n",
      "[5, 53, 28, 8, 2821, 11, 127, 161, 22, 15, 225, 5, 202, 8, 25, 87] [53, 28, 8, 2821, 11, 127, 161, 22, 15, 225, 5, 202, 8, 25, 87, 111]\n",
      "[53, 28, 8, 2821, 11, 127, 161, 22, 15, 225, 5, 202, 8, 25, 87, 111] [28, 8, 2821, 11, 127, 161, 22, 15, 225, 5, 202, 8, 25, 87, 111, 35]\n",
      "[28, 8, 2821, 11, 127, 161, 22, 15, 225, 5, 202, 8, 25, 87, 111, 35] [8, 2821, 11, 127, 161, 22, 15, 225, 5, 202, 8, 25, 87, 111, 35, 15]\n",
      "[8, 2821, 11, 127, 161, 22, 15, 225, 5, 202, 8, 25, 87, 111, 35, 15] [2821, 11, 127, 161, 22, 15, 225, 5, 202, 8, 25, 87, 111, 35, 15, 1275]\n",
      "[2821, 11, 127, 161, 22, 15, 225, 5, 202, 8, 25, 87, 111, 35, 15, 1275] [11, 127, 161, 22, 15, 225, 5, 202, 8, 25, 87, 111, 35, 15, 1275, 490]\n",
      "[11, 127, 161, 22, 15, 225, 5, 202, 8, 25, 87, 111, 35, 15, 1275, 490] [127, 161, 22, 15, 225, 5, 202, 8, 25, 87, 111, 35, 15, 1275, 490, 111]\n",
      "[127, 161, 22, 15, 225, 5, 202, 8, 25, 87, 111, 35, 15, 1275, 490, 111] [161, 22, 15, 225, 5, 202, 8, 25, 87, 111, 35, 15, 1275, 490, 111, 5795]\n",
      "[161, 22, 15, 225, 5, 202, 8, 25, 87, 111, 35, 15, 1275, 490, 111, 5795] [22, 15, 225, 5, 202, 8, 25, 87, 111, 35, 15, 1275, 490, 111, 5795, 15]\n",
      "[22, 15, 225, 5, 202, 8, 25, 87, 111, 35, 15, 1275, 490, 111, 5795, 15] [15, 225, 5, 202, 8, 25, 87, 111, 35, 15, 1275, 490, 111, 5795, 15, 5]\n",
      "[15, 225, 5, 202, 8, 25, 87, 111, 35, 15, 1275, 490, 111, 5795, 15, 5] [225, 5, 202, 8, 25, 87, 111, 35, 15, 1275, 490, 111, 5795, 15, 5, 43]\n",
      "[225, 5, 202, 8, 25, 87, 111, 35, 15, 1275, 490, 111, 5795, 15, 5, 43] [5, 202, 8, 25, 87, 111, 35, 15, 1275, 490, 111, 5795, 15, 5, 43, 11]\n",
      "[5, 202, 8, 25, 87, 111, 35, 15, 1275, 490, 111, 5795, 15, 5, 43, 11] [202, 8, 25, 87, 111, 35, 15, 1275, 490, 111, 5795, 15, 5, 43, 11, 10]\n",
      "[202, 8, 25, 87, 111, 35, 15, 1275, 490, 111, 5795, 15, 5, 43, 11, 10] [8, 25, 87, 111, 35, 15, 1275, 490, 111, 5795, 15, 5, 43, 11, 10, 48]\n",
      "[8, 25, 87, 111, 35, 15, 1275, 490, 111, 5795, 15, 5, 43, 11, 10, 48] [25, 87, 111, 35, 15, 1275, 490, 111, 5795, 15, 5, 43, 11, 10, 48, 8]\n",
      "[25, 87, 111, 35, 15, 1275, 490, 111, 5795, 15, 5, 43, 11, 10, 48, 8] [87, 111, 35, 15, 1275, 490, 111, 5795, 15, 5, 43, 11, 10, 48, 8, 772]\n",
      "[87, 111, 35, 15, 1275, 490, 111, 5795, 15, 5, 43, 11, 10, 48, 8, 772] [111, 35, 15, 1275, 490, 111, 5795, 15, 5, 43, 11, 10, 48, 8, 772, 723]\n",
      "[111, 35, 15, 1275, 490, 111, 5795, 15, 5, 43, 11, 10, 48, 8, 772, 723] [35, 15, 1275, 490, 111, 5795, 15, 5, 43, 11, 10, 48, 8, 772, 723, 38]\n",
      "[35, 15, 1275, 490, 111, 5795, 15, 5, 43, 11, 10, 48, 8, 772, 723, 38] [15, 1275, 490, 111, 5795, 15, 5, 43, 11, 10, 48, 8, 772, 723, 38, 2821]\n",
      "[15, 1275, 490, 111, 5795, 15, 5, 43, 11, 10, 48, 8, 772, 723, 38, 2821] [1275, 490, 111, 5795, 15, 5, 43, 11, 10, 48, 8, 772, 723, 38, 2821, 985]\n",
      "[1275, 490, 111, 5795, 15, 5, 43, 11, 10, 48, 8, 772, 723, 38, 2821, 985] [490, 111, 5795, 15, 5, 43, 11, 10, 48, 8, 772, 723, 38, 2821, 985, 6]\n",
      "[490, 111, 5795, 15, 5, 43, 11, 10, 48, 8, 772, 723, 38, 2821, 985, 6] [111, 5795, 15, 5, 43, 11, 10, 48, 8, 772, 723, 38, 2821, 985, 6, 184]\n",
      "[111, 5795, 15, 5, 43, 11, 10, 48, 8, 772, 723, 38, 2821, 985, 6, 184] [5795, 15, 5, 43, 11, 10, 48, 8, 772, 723, 38, 2821, 985, 6, 184, 9]\n",
      "[5795, 15, 5, 43, 11, 10, 48, 8, 772, 723, 38, 2821, 985, 6, 184, 9] [15, 5, 43, 11, 10, 48, 8, 772, 723, 38, 2821, 985, 6, 184, 9, 150]\n",
      "[15, 5, 43, 11, 10, 48, 8, 772, 723, 38, 2821, 985, 6, 184, 9, 150] [5, 43, 11, 10, 48, 8, 772, 723, 38, 2821, 985, 6, 184, 9, 150, 105]\n",
      "[5, 43, 11, 10, 48, 8, 772, 723, 38, 2821, 985, 6, 184, 9, 150, 105] [43, 11, 10, 48, 8, 772, 723, 38, 2821, 985, 6, 184, 9, 150, 105, 8]\n",
      "[43, 11, 10, 48, 8, 772, 723, 38, 2821, 985, 6, 184, 9, 150, 105, 8] [11, 10, 48, 8, 772, 723, 38, 2821, 985, 6, 184, 9, 150, 105, 8, 55]\n",
      "[11, 10, 48, 8, 772, 723, 38, 2821, 985, 6, 184, 9, 150, 105, 8, 55] [10, 48, 8, 772, 723, 38, 2821, 985, 6, 184, 9, 150, 105, 8, 55, 7]\n",
      "[10, 48, 8, 772, 723, 38, 2821, 985, 6, 184, 9, 150, 105, 8, 55, 7] [48, 8, 772, 723, 38, 2821, 985, 6, 184, 9, 150, 105, 8, 55, 7, 723]\n",
      "[48, 8, 772, 723, 38, 2821, 985, 6, 184, 9, 150, 105, 8, 55, 7, 723] [8, 772, 723, 38, 2821, 985, 6, 184, 9, 150, 105, 8, 55, 7, 723, 272]\n",
      "[8, 772, 723, 38, 2821, 985, 6, 184, 9, 150, 105, 8, 55, 7, 723, 272] [772, 723, 38, 2821, 985, 6, 184, 9, 150, 105, 8, 55, 7, 723, 272, 2746]\n",
      "[772, 723, 38, 2821, 985, 6, 184, 9, 150, 105, 8, 55, 7, 723, 272, 2746] [723, 38, 2821, 985, 6, 184, 9, 150, 105, 8, 55, 7, 723, 272, 2746, 15]\n",
      "[723, 38, 2821, 985, 6, 184, 9, 150, 105, 8, 55, 7, 723, 272, 2746, 15] [38, 2821, 985, 6, 184, 9, 150, 105, 8, 55, 7, 723, 272, 2746, 15, 5]\n",
      "[38, 2821, 985, 6, 184, 9, 150, 105, 8, 55, 7, 723, 272, 2746, 15, 5] [2821, 985, 6, 184, 9, 150, 105, 8, 55, 7, 723, 272, 2746, 15, 5, 14]\n",
      "[2821, 985, 6, 184, 9, 150, 105, 8, 55, 7, 723, 272, 2746, 15, 5, 14] [985, 6, 184, 9, 150, 105, 8, 55, 7, 723, 272, 2746, 15, 5, 14, 184]\n",
      "[985, 6, 184, 9, 150, 105, 8, 55, 7, 723, 272, 2746, 15, 5, 14, 184] [6, 184, 9, 150, 105, 8, 55, 7, 723, 272, 2746, 15, 5, 14, 184, 9]\n",
      "[6, 184, 9, 150, 105, 8, 55, 7, 723, 272, 2746, 15, 5, 14, 184, 9] [184, 9, 150, 105, 8, 55, 7, 723, 272, 2746, 15, 5, 14, 184, 9, 285]\n",
      "[184, 9, 150, 105, 8, 55, 7, 723, 272, 2746, 15, 5, 14, 184, 9, 285] [9, 150, 105, 8, 55, 7, 723, 272, 2746, 15, 5, 14, 184, 9, 285, 6]\n",
      "[9, 150, 105, 8, 55, 7, 723, 272, 2746, 15, 5, 14, 184, 9, 285, 6] [150, 105, 8, 55, 7, 723, 272, 2746, 15, 5, 14, 184, 9, 285, 6, 638]\n",
      "[150, 105, 8, 55, 7, 723, 272, 2746, 15, 5, 14, 184, 9, 285, 6, 638] [105, 8, 55, 7, 723, 272, 2746, 15, 5, 14, 184, 9, 285, 6, 638, 8]\n",
      "[105, 8, 55, 7, 723, 272, 2746, 15, 5, 14, 184, 9, 285, 6, 638, 8] [8, 55, 7, 723, 272, 2746, 15, 5, 14, 184, 9, 285, 6, 638, 8, 55]\n",
      "[8, 55, 7, 723, 272, 2746, 15, 5, 14, 184, 9, 285, 6, 638, 8, 55] [55, 7, 723, 272, 2746, 15, 5, 14, 184, 9, 285, 6, 638, 8, 55, 12]\n",
      "[55, 7, 723, 272, 2746, 15, 5, 14, 184, 9, 285, 6, 638, 8, 55, 12] [7, 723, 272, 2746, 15, 5, 14, 184, 9, 285, 6, 638, 8, 55, 12, 11]\n",
      "[7, 723, 272, 2746, 15, 5, 14, 184, 9, 285, 6, 638, 8, 55, 12, 11] [723, 272, 2746, 15, 5, 14, 184, 9, 285, 6, 638, 8, 55, 12, 11, 80]\n",
      "[723, 272, 2746, 15, 5, 14, 184, 9, 285, 6, 638, 8, 55, 12, 11, 80] [272, 2746, 15, 5, 14, 184, 9, 285, 6, 638, 8, 55, 12, 11, 80, 2233]\n",
      "[272, 2746, 15, 5, 14, 184, 9, 285, 6, 638, 8, 55, 12, 11, 80, 2233] [2746, 15, 5, 14, 184, 9, 285, 6, 638, 8, 55, 12, 11, 80, 2233, 5]\n",
      "[2746, 15, 5, 14, 184, 9, 285, 6, 638, 8, 55, 12, 11, 80, 2233, 5] [15, 5, 14, 184, 9, 285, 6, 638, 8, 55, 12, 11, 80, 2233, 5, 2821]\n",
      "[15, 5, 14, 184, 9, 285, 6, 638, 8, 55, 12, 11, 80, 2233, 5, 2821] [5, 14, 184, 9, 285, 6, 638, 8, 55, 12, 11, 80, 2233, 5, 2821, 18]\n",
      "[5, 14, 184, 9, 285, 6, 638, 8, 55, 12, 11, 80, 2233, 5, 2821, 18] [14, 184, 9, 285, 6, 638, 8, 55, 12, 11, 80, 2233, 5, 2821, 18, 23]\n",
      "[14, 184, 9, 285, 6, 638, 8, 55, 12, 11, 80, 2233, 5, 2821, 18, 23] [184, 9, 285, 6, 638, 8, 55, 12, 11, 80, 2233, 5, 2821, 18, 23, 464]\n",
      "[184, 9, 285, 6, 638, 8, 55, 12, 11, 80, 2233, 5, 2821, 18, 23, 464] [9, 285, 6, 638, 8, 55, 12, 11, 80, 2233, 5, 2821, 18, 23, 464, 191]\n",
      "[9, 285, 6, 638, 8, 55, 12, 11, 80, 2233, 5, 2821, 18, 23, 464, 191] [285, 6, 638, 8, 55, 12, 11, 80, 2233, 5, 2821, 18, 23, 464, 191, 15]\n",
      "[285, 6, 638, 8, 55, 12, 11, 80, 2233, 5, 2821, 18, 23, 464, 191, 15] [6, 638, 8, 55, 12, 11, 80, 2233, 5, 2821, 18, 23, 464, 191, 15, 1233]\n",
      "[6, 638, 8, 55, 12, 11, 80, 2233, 5, 2821, 18, 23, 464, 191, 15, 1233] [638, 8, 55, 12, 11, 80, 2233, 5, 2821, 18, 23, 464, 191, 15, 1233, 6]\n",
      "[638, 8, 55, 12, 11, 80, 2233, 5, 2821, 18, 23, 464, 191, 15, 1233, 6] [8, 55, 12, 11, 80, 2233, 5, 2821, 18, 23, 464, 191, 15, 1233, 6, 137]\n",
      "[8, 55, 12, 11, 80, 2233, 5, 2821, 18, 23, 464, 191, 15, 1233, 6, 137] [55, 12, 11, 80, 2233, 5, 2821, 18, 23, 464, 191, 15, 1233, 6, 137, 483]\n",
      "[55, 12, 11, 80, 2233, 5, 2821, 18, 23, 464, 191, 15, 1233, 6, 137, 483] [12, 11, 80, 2233, 5, 2821, 18, 23, 464, 191, 15, 1233, 6, 137, 483, 5]\n",
      "[12, 11, 80, 2233, 5, 2821, 18, 23, 464, 191, 15, 1233, 6, 137, 483, 5] [11, 80, 2233, 5, 2821, 18, 23, 464, 191, 15, 1233, 6, 137, 483, 5, 17]\n",
      "[11, 80, 2233, 5, 2821, 18, 23, 464, 191, 15, 1233, 6, 137, 483, 5, 17] [80, 2233, 5, 2821, 18, 23, 464, 191, 15, 1233, 6, 137, 483, 5, 17, 457]\n",
      "[80, 2233, 5, 2821, 18, 23, 464, 191, 15, 1233, 6, 137, 483, 5, 17, 457] [2233, 5, 2821, 18, 23, 464, 191, 15, 1233, 6, 137, 483, 5, 17, 457, 10]\n",
      "[2233, 5, 2821, 18, 23, 464, 191, 15, 1233, 6, 137, 483, 5, 17, 457, 10] [5, 2821, 18, 23, 464, 191, 15, 1233, 6, 137, 483, 5, 17, 457, 10, 549]\n",
      "[5, 2821, 18, 23, 464, 191, 15, 1233, 6, 137, 483, 5, 17, 457, 10, 549] [2821, 18, 23, 464, 191, 15, 1233, 6, 137, 483, 5, 17, 457, 10, 549, 9]\n",
      "[2821, 18, 23, 464, 191, 15, 1233, 6, 137, 483, 5, 17, 457, 10, 549, 9] [18, 23, 464, 191, 15, 1233, 6, 137, 483, 5, 17, 457, 10, 549, 9, 97]\n",
      "[18, 23, 464, 191, 15, 1233, 6, 137, 483, 5, 17, 457, 10, 549, 9, 97] [23, 464, 191, 15, 1233, 6, 137, 483, 5, 17, 457, 10, 549, 9, 97, 15]\n",
      "[23, 464, 191, 15, 1233, 6, 137, 483, 5, 17, 457, 10, 549, 9, 97, 15] [464, 191, 15, 1233, 6, 137, 483, 5, 17, 457, 10, 549, 9, 97, 15, 150]\n",
      "[464, 191, 15, 1233, 6, 137, 483, 5, 17, 457, 10, 549, 9, 97, 15, 150] [191, 15, 1233, 6, 137, 483, 5, 17, 457, 10, 549, 9, 97, 15, 150, 3664]\n",
      "[191, 15, 1233, 6, 137, 483, 5, 17, 457, 10, 549, 9, 97, 15, 150, 3664] [15, 1233, 6, 137, 483, 5, 17, 457, 10, 549, 9, 97, 15, 150, 3664, 30]\n",
      "[15, 1233, 6, 137, 483, 5, 17, 457, 10, 549, 9, 97, 15, 150, 3664, 30] [1233, 6, 137, 483, 5, 17, 457, 10, 549, 9, 97, 15, 150, 3664, 30, 7]\n",
      "[1233, 6, 137, 483, 5, 17, 457, 10, 549, 9, 97, 15, 150, 3664, 30, 7] [6, 137, 483, 5, 17, 457, 10, 549, 9, 97, 15, 150, 3664, 30, 7, 723]\n",
      "[6, 137, 483, 5, 17, 457, 10, 549, 9, 97, 15, 150, 3664, 30, 7, 723] [137, 483, 5, 17, 457, 10, 549, 9, 97, 15, 150, 3664, 30, 7, 723, 5]\n",
      "[137, 483, 5, 17, 457, 10, 549, 9, 97, 15, 150, 3664, 30, 7, 723, 5] [483, 5, 17, 457, 10, 549, 9, 97, 15, 150, 3664, 30, 7, 723, 5, 274]\n",
      "[483, 5, 17, 457, 10, 549, 9, 97, 15, 150, 3664, 30, 7, 723, 5, 274] [5, 17, 457, 10, 549, 9, 97, 15, 150, 3664, 30, 7, 723, 5, 274, 7]\n",
      "[5, 17, 457, 10, 549, 9, 97, 15, 150, 3664, 30, 7, 723, 5, 274, 7] [17, 457, 10, 549, 9, 97, 15, 150, 3664, 30, 7, 723, 5, 274, 7, 723]\n",
      "[17, 457, 10, 549, 9, 97, 15, 150, 3664, 30, 7, 723, 5, 274, 7, 723] [457, 10, 549, 9, 97, 15, 150, 3664, 30, 7, 723, 5, 274, 7, 723, 11]\n",
      "[457, 10, 549, 9, 97, 15, 150, 3664, 30, 7, 723, 5, 274, 7, 723, 11] [10, 549, 9, 97, 15, 150, 3664, 30, 7, 723, 5, 274, 7, 723, 11, 553]\n",
      "[10, 549, 9, 97, 15, 150, 3664, 30, 7, 723, 5, 274, 7, 723, 11, 553] [549, 9, 97, 15, 150, 3664, 30, 7, 723, 5, 274, 7, 723, 11, 553, 8]\n",
      "[549, 9, 97, 15, 150, 3664, 30, 7, 723, 5, 274, 7, 723, 11, 553, 8] [9, 97, 15, 150, 3664, 30, 7, 723, 5, 274, 7, 723, 11, 553, 8, 33]\n",
      "[9, 97, 15, 150, 3664, 30, 7, 723, 5, 274, 7, 723, 11, 553, 8, 33] [97, 15, 150, 3664, 30, 7, 723, 5, 274, 7, 723, 11, 553, 8, 33, 206]\n",
      "[97, 15, 150, 3664, 30, 7, 723, 5, 274, 7, 723, 11, 553, 8, 33, 206] [15, 150, 3664, 30, 7, 723, 5, 274, 7, 723, 11, 553, 8, 33, 206, 2821]\n",
      "[15, 150, 3664, 30, 7, 723, 5, 274, 7, 723, 11, 553, 8, 33, 206, 2821] [150, 3664, 30, 7, 723, 5, 274, 7, 723, 11, 553, 8, 33, 206, 2821, 6]\n",
      "[150, 3664, 30, 7, 723, 5, 274, 7, 723, 11, 553, 8, 33, 206, 2821, 6] [3664, 30, 7, 723, 5, 274, 7, 723, 11, 553, 8, 33, 206, 2821, 6, 188]\n",
      "[3664, 30, 7, 723, 5, 274, 7, 723, 11, 553, 8, 33, 206, 2821, 6, 188] [30, 7, 723, 5, 274, 7, 723, 11, 553, 8, 33, 206, 2821, 6, 188, 15]\n",
      "[30, 7, 723, 5, 274, 7, 723, 11, 553, 8, 33, 206, 2821, 6, 188, 15] [7, 723, 5, 274, 7, 723, 11, 553, 8, 33, 206, 2821, 6, 188, 15, 630]\n",
      "[7, 723, 5, 274, 7, 723, 11, 553, 8, 33, 206, 2821, 6, 188, 15, 630] [723, 5, 274, 7, 723, 11, 553, 8, 33, 206, 2821, 6, 188, 15, 630, 100]\n",
      "[723, 5, 274, 7, 723, 11, 553, 8, 33, 206, 2821, 6, 188, 15, 630, 100] [5, 274, 7, 723, 11, 553, 8, 33, 206, 2821, 6, 188, 15, 630, 100, 68]\n",
      "[5, 274, 7, 723, 11, 553, 8, 33, 206, 2821, 6, 188, 15, 630, 100, 68] [274, 7, 723, 11, 553, 8, 33, 206, 2821, 6, 188, 15, 630, 100, 68, 2799]\n",
      "[274, 7, 723, 11, 553, 8, 33, 206, 2821, 6, 188, 15, 630, 100, 68, 2799] [7, 723, 11, 553, 8, 33, 206, 2821, 6, 188, 15, 630, 100, 68, 2799, 5]\n",
      "[7, 723, 11, 553, 8, 33, 206, 2821, 6, 188, 15, 630, 100, 68, 2799, 5] [723, 11, 553, 8, 33, 206, 2821, 6, 188, 15, 630, 100, 68, 2799, 5, 170]\n",
      "[723, 11, 553, 8, 33, 206, 2821, 6, 188, 15, 630, 100, 68, 2799, 5, 170] [11, 553, 8, 33, 206, 2821, 6, 188, 15, 630, 100, 68, 2799, 5, 170, 7]\n",
      "[11, 553, 8, 33, 206, 2821, 6, 188, 15, 630, 100, 68, 2799, 5, 170, 7] [553, 8, 33, 206, 2821, 6, 188, 15, 630, 100, 68, 2799, 5, 170, 7, 723]\n",
      "[553, 8, 33, 206, 2821, 6, 188, 15, 630, 100, 68, 2799, 5, 170, 7, 723] [8, 33, 206, 2821, 6, 188, 15, 630, 100, 68, 2799, 5, 170, 7, 723, 11]\n",
      "[8, 33, 206, 2821, 6, 188, 15, 630, 100, 68, 2799, 5, 170, 7, 723, 11] [33, 206, 2821, 6, 188, 15, 630, 100, 68, 2799, 5, 170, 7, 723, 11, 553]\n",
      "[33, 206, 2821, 6, 188, 15, 630, 100, 68, 2799, 5, 170, 7, 723, 11, 553] [206, 2821, 6, 188, 15, 630, 100, 68, 2799, 5, 170, 7, 723, 11, 553, 8]\n",
      "[206, 2821, 6, 188, 15, 630, 100, 68, 2799, 5, 170, 7, 723, 11, 553, 8] [2821, 6, 188, 15, 630, 100, 68, 2799, 5, 170, 7, 723, 11, 553, 8, 2821]\n",
      "[2821, 6, 188, 15, 630, 100, 68, 2799, 5, 170, 7, 723, 11, 553, 8, 2821] [6, 188, 15, 630, 100, 68, 2799, 5, 170, 7, 723, 11, 553, 8, 2821, 87]\n",
      "[6, 188, 15, 630, 100, 68, 2799, 5, 170, 7, 723, 11, 553, 8, 2821, 87] [188, 15, 630, 100, 68, 2799, 5, 170, 7, 723, 11, 553, 8, 2821, 87, 900]\n",
      "[188, 15, 630, 100, 68, 2799, 5, 170, 7, 723, 11, 553, 8, 2821, 87, 900] [15, 630, 100, 68, 2799, 5, 170, 7, 723, 11, 553, 8, 2821, 87, 900, 6]\n",
      "[15, 630, 100, 68, 2799, 5, 170, 7, 723, 11, 553, 8, 2821, 87, 900, 6] [630, 100, 68, 2799, 5, 170, 7, 723, 11, 553, 8, 2821, 87, 900, 6, 44]\n",
      "[630, 100, 68, 2799, 5, 170, 7, 723, 11, 553, 8, 2821, 87, 900, 6, 44] [100, 68, 2799, 5, 170, 7, 723, 11, 553, 8, 2821, 87, 900, 6, 44, 5]\n",
      "[100, 68, 2799, 5, 170, 7, 723, 11, 553, 8, 2821, 87, 900, 6, 44, 5] [68, 2799, 5, 170, 7, 723, 11, 553, 8, 2821, 87, 900, 6, 44, 5, 14]\n",
      "[68, 2799, 5, 170, 7, 723, 11, 553, 8, 2821, 87, 900, 6, 44, 5, 14] [2799, 5, 170, 7, 723, 11, 553, 8, 2821, 87, 900, 6, 44, 5, 14, 71]\n",
      "[2799, 5, 170, 7, 723, 11, 553, 8, 2821, 87, 900, 6, 44, 5, 14, 71] [5, 170, 7, 723, 11, 553, 8, 2821, 87, 900, 6, 44, 5, 14, 71, 79]\n",
      "[5, 170, 7, 723, 11, 553, 8, 2821, 87, 900, 6, 44, 5, 14, 71, 79] [170, 7, 723, 11, 553, 8, 2821, 87, 900, 6, 44, 5, 14, 71, 79, 9]\n",
      "[170, 7, 723, 11, 553, 8, 2821, 87, 900, 6, 44, 5, 14, 71, 79, 9] [7, 723, 11, 553, 8, 2821, 87, 900, 6, 44, 5, 14, 71, 79, 9, 127]\n",
      "[7, 723, 11, 553, 8, 2821, 87, 900, 6, 44, 5, 14, 71, 79, 9, 127] [723, 11, 553, 8, 2821, 87, 900, 6, 44, 5, 14, 71, 79, 9, 127, 22]\n",
      "[723, 11, 553, 8, 2821, 87, 900, 6, 44, 5, 14, 71, 79, 9, 127, 22] [11, 553, 8, 2821, 87, 900, 6, 44, 5, 14, 71, 79, 9, 127, 22, 7]\n",
      "[11, 553, 8, 2821, 87, 900, 6, 44, 5, 14, 71, 79, 9, 127, 22, 7] [553, 8, 2821, 87, 900, 6, 44, 5, 14, 71, 79, 9, 127, 22, 7, 225]\n",
      "[553, 8, 2821, 87, 900, 6, 44, 5, 14, 71, 79, 9, 127, 22, 7, 225] [8, 2821, 87, 900, 6, 44, 5, 14, 71, 79, 9, 127, 22, 7, 225, 8]\n",
      "[8, 2821, 87, 900, 6, 44, 5, 14, 71, 79, 9, 127, 22, 7, 225, 8] [2821, 87, 900, 6, 44, 5, 14, 71, 79, 9, 127, 22, 7, 225, 8, 432]\n",
      "[2821, 87, 900, 6, 44, 5, 14, 71, 79, 9, 127, 22, 7, 225, 8, 432] [87, 900, 6, 44, 5, 14, 71, 79, 9, 127, 22, 7, 225, 8, 432, 359]\n",
      "[87, 900, 6, 44, 5, 14, 71, 79, 9, 127, 22, 7, 225, 8, 432, 359] [900, 6, 44, 5, 14, 71, 79, 9, 127, 22, 7, 225, 8, 432, 359, 25]\n",
      "[900, 6, 44, 5, 14, 71, 79, 9, 127, 22, 7, 225, 8, 432, 359, 25] [6, 44, 5, 14, 71, 79, 9, 127, 22, 7, 225, 8, 432, 359, 25, 154]\n",
      "[6, 44, 5, 14, 71, 79, 9, 127, 22, 7, 225, 8, 432, 359, 25, 154] [44, 5, 14, 71, 79, 9, 127, 22, 7, 225, 8, 432, 359, 25, 154, 18]\n",
      "[44, 5, 14, 71, 79, 9, 127, 22, 7, 225, 8, 432, 359, 25, 154, 18] [5, 14, 71, 79, 9, 127, 22, 7, 225, 8, 432, 359, 25, 154, 18, 47]\n",
      "[5, 14, 71, 79, 9, 127, 22, 7, 225, 8, 432, 359, 25, 154, 18, 47] [14, 71, 79, 9, 127, 22, 7, 225, 8, 432, 359, 25, 154, 18, 47, 1555]\n",
      "[14, 71, 79, 9, 127, 22, 7, 225, 8, 432, 359, 25, 154, 18, 47, 1555] [71, 79, 9, 127, 22, 7, 225, 8, 432, 359, 25, 154, 18, 47, 1555, 35]\n",
      "[71, 79, 9, 127, 22, 7, 225, 8, 432, 359, 25, 154, 18, 47, 1555, 35] [79, 9, 127, 22, 7, 225, 8, 432, 359, 25, 154, 18, 47, 1555, 35, 572]\n",
      "[79, 9, 127, 22, 7, 225, 8, 432, 359, 25, 154, 18, 47, 1555, 35, 572] [9, 127, 22, 7, 225, 8, 432, 359, 25, 154, 18, 47, 1555, 35, 572, 162]\n",
      "[9, 127, 22, 7, 225, 8, 432, 359, 25, 154, 18, 47, 1555, 35, 572, 162] [127, 22, 7, 225, 8, 432, 359, 25, 154, 18, 47, 1555, 35, 572, 162, 1074]\n",
      "[127, 22, 7, 225, 8, 432, 359, 25, 154, 18, 47, 1555, 35, 572, 162, 1074] [22, 7, 225, 8, 432, 359, 25, 154, 18, 47, 1555, 35, 572, 162, 1074, 5]\n"
     ]
    }
   ],
   "source": [
    "# Lets create a dataset\n",
    "T = 16  # Window size\n",
    "V = VOCAB_SIZE\n",
    "B = 64\n",
    "SOS = \"<SOS>\"\n",
    "EOS = \"<EOS>\"\n",
    "\n",
    "\n",
    "# This is a bit slow because it generates S*(N - T) samples of length T each, where S is the number of sentences and N is the number of tokens in the sentence\n",
    "# TODO: stupidly parallelize and load it into a numpy array and save it to a file, then memory map that file and load it into a torch tensor.\n",
    "def data_generator(tokens):\n",
    "    xy = []  # x: T word window, y is T+1th word\n",
    "\n",
    "    for sentence_tokens in tokens:\n",
    "        for i in range(0, len(sentence_tokens) - T):\n",
    "            yield sentence_tokens[i : i + T], sentence_tokens[i + 1 : (i + T + 1)]\n",
    "\n",
    "\n",
    "for x, y in data_generator(sp_processor.encode_as_ids(all_sentences[100:101])):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<SOS>One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\\n\\nLily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\"\\n\\nTogether, they shared the needle and sewed the button on Lily\\'s shirt. It was not difficult for them because they were sharing and helping each other. After they finished, Lily thanked her mom for sharing the needle and fixing her shirt. They both felt happy because they had shared and worked together.<EOS>',\n",
       " '<SOS>Once upon a time, there was a little car named Beep. Beep loved to go fast and play in the sun. Beep was a healthy car because he always had good fuel. Good fuel made Beep happy and strong.\\n\\nOne day, Beep was driving in the park when he saw a big tree. The tree had many leaves that were falling. Beep liked how the leaves fall and wanted to play with them. Beep drove under the tree and watched the leaves fall on him. He laughed and beeped his horn.\\n\\nBeep played with the falling leaves all day. When it was time to go home, Beep knew he needed more fuel. He went to the fuel place and got more healthy fuel. Now, Beep was ready to go fast and play again the next day. And Beep lived happily ever after.<EOS>',\n",
       " '<SOS>One day, a little fish named Fin was swimming near the shore. He saw a big crab and wanted to be friends. \"Hi, I am Fin. Do you want to play?\" asked the little fish. The crab looked at Fin and said, \"No, I don\\'t want to play. I am cold and I don\\'t feel fine.\"\\n\\nFin felt sad but wanted to help the crab feel better. He swam away and thought of a plan. He remembered that the sun could make things warm. So, Fin swam to the top of the water and called to the sun, \"Please, sun, help my new friend feel fine and not freeze!\"\\n\\nThe sun heard Fin\\'s call and shone its warm light on the shore. The crab started to feel better and not so cold. He saw Fin and said, \"Thank you, little fish, for making me feel fine. I don\\'t feel like I will freeze now. Let\\'s play together!\" And so, Fin and the crab played and became good friends.<EOS>',\n",
       " '<SOS>Once upon a time, in a land full of trees, there was a little cherry tree. The cherry tree was very sad because it did not have any friends. All the other trees were big and strong, but the cherry tree was small and weak. The cherry tree was envious of the big trees.\\n\\nOne day, the cherry tree felt a tickle in its branches. It was a little spring wind. The wind told the cherry tree not to be sad. The wind said, \"You are special because you have sweet cherries that everyone loves.\" The cherry tree started to feel a little better.\\n\\nAs time went on, the cherry tree grew more and more cherries. All the animals in the land came to eat the cherries and play under the cherry tree. The cherry tree was happy because it had many friends now. The cherry tree learned that being different can be a good thing. And they all lived happily ever after.<EOS>',\n",
       " '<SOS>Once upon a time, there was a little girl named Lily. Lily liked to pretend she was a popular princess. She lived in a big castle with her best friends, a cat and a dog.\\n\\nOne day, while playing in the castle, Lily found a big cobweb. The cobweb was in the way of her fun game. She wanted to get rid of it, but she was scared of the spider that lived there.\\n\\nLily asked her friends, the cat and the dog, to help her. They all worked together to clean the cobweb. The spider was sad, but it found a new home outside. Lily, the cat, and the dog were happy they could play without the cobweb in the way. And they all lived happily ever after.<EOS>',\n",
       " '<SOS>Once upon a time, in a big lake, there was a brown kayak. The brown kayak liked to roll in the water all day long. It was very happy when it could roll and splash in the lake.\\n\\nOne day, a little boy named Tim came to play with the brown kayak. Tim and the brown kayak rolled in the water together. They laughed and had a lot of fun. The sun was shining, and the water was warm.\\n\\nAfter a while, it was time for Tim to go home. He said goodbye to the brown kayak and gave it a big hug. The brown kayak was sad to see Tim go, but it knew they would play together again soon. So, the brown kayak kept rolling in the water, waiting for the next fun day with Tim.<EOS>',\n",
       " '<SOS>Once upon a time, in a small town, there was a troubled little girl named Lily. She was always sad because she lost her favorite toy, a triangle. She looked everywhere in her house but could not find it.\\n\\nOne sunny day, Lily went to the park to play. She saw a big puddle of water and thought her triangle might be there. She put her hand in the water to soak it and looked for her toy. She felt something at the bottom of the puddle.\\n\\nLily pulled it out and saw that it was her triangle! She was so happy that she found it. From that day on, Lily was never troubled again. She played with her triangle every day and always kept it close to her. And when she saw puddles, she would smile and remember how she found her toy.<EOS>',\n",
       " '<SOS>Once upon a time, in a peaceful town, there lived a little boy named Tim. Tim loved to run and play outside. One day, Tim saw a race in the park. He was excited and wanted to join the race.\\n\\nTim went to his friend, Sarah, and said, \"Let\\'s start the race!\" Sarah smiled and said, \"Yes, let\\'s go!\" They lined up with the other kids and waited for the race to begin. When they heard the word \"Go!\", they started running as fast as they could.\\n\\nTim and Sarah ran with all their speed, laughing and having fun. They could feel the wind in their hair as they raced to the finish line. In the end, Tim won the race and Sarah came in second. They were both so happy and proud of themselves. They celebrated with their friends and had a great day at the park.<EOS>',\n",
       " '<SOS>Once upon a time, there was a clever little dog named Max. Max loved to run and play with his friends in the park. One day, Max was running very fast when he fell and hurt his knee.\\n\\nMax went to his friend, the wise old owl, and said, \"Owl, my knee hurts. What can I do?\" The owl thought for a moment and said, \"Max, you should test your knee. Try to walk slowly and see if it still hurts.\"\\n\\nSo Max tested his knee by walking slowly. At first, it hurt a little, but soon Max felt better. He said, \"Thank you, Owl, for your help. Now I can play with my friends again.\"\\n\\nMax was so happy that he could play with his friends without pain. He learned that sometimes, it was good to slow down and listen to his body. And Max and his friends played happily in the park ever after.<EOS>',\n",
       " '<SOS>One day, a fast driver named Tim went for a ride in his loud car. He loved to speed down the street and feel the wind in his hair. As he drove, he saw his friend, Sam, standing by the road.\\n\\n\"Hi, Sam!\" Tim called out. \"Do you want to go for a ride?\"\\n\\n\"Yes, please!\" Sam said, and he got in the car. They drove around the town, going fast and having fun. The car was very loud, and everyone could hear them coming.\\n\\nAt last, they stopped at the park to play. They ran and laughed until it was time to go home. Tim and Sam had a great day together, speeding in the loud car and playing in the park.<EOS>',\n",
       " '<SOS>Once upon a time, there was a big car named Dependable. He had a very important job. Dependable would take a family to the park every day. The family had a mom, dad, and a little girl named Lily. They all had a lot of love for each other.\\n\\nOne day, when they got to the park, they saw a big sign that said, \"Fun Race Today!\" The family was very excited. They knew that Dependable was very fast and could win the race. So, they decided to join the race.\\n\\nThe race started, and Dependable went very fast. The other cars tried to catch up, but Dependable was too quick. In the end, Dependable won the race! The family was so happy and proud of their car. They knew that their love for each other and their trust in Dependable made them win the race. And from that day on, they had even more fun at the park, knowing that they had the fastest and most dependable car around.<EOS>',\n",
       " '<SOS>Once upon a time, there was a boy named Tim. He liked to wear a big, dark hat. The hat was his favorite thing to wear. Tim wore the hat everywhere he went.\\n\\nOne day, Tim found a pencil on the ground. The pencil was small and yellow. Tim liked the pencil a lot. He put the pencil in his hat and took it with him.\\n\\nTim drew pictures with the pencil. He drew a sun, a tree, and a cat. Tim was very happy with his new pencil. He wore his dark hat and drew pictures every day.<EOS>',\n",
       " '<SOS>One day, a girl named Mia went for a walk. She saw a big, scary house. It had a tall door and small windows. Mia was brave, so she went inside the house.\\n\\nIn the house, Mia saw a birdcage. Inside the birdcage, there was a little bird. The bird was sad. It wanted to fly and be free. Mia wanted to help the bird.\\n\\nMia opened the birdcage door. The bird flew out and was happy. It was not scary anymore. Mia and the bird were friends. They played and had fun all day.<EOS>',\n",
       " '<SOS>Once upon a time, in a small house, there lived a little girl named Amy. Amy was very sleepy. She put on her pajamas and went to bed.\\n\\nIn the middle of the night, Amy heard a soft sound. She opened her eyes and saw a friendly ghost. The ghost said, \"Hello, Amy! I am here to help you.\"\\n\\nAmy asked the ghost, \"Can you help me pick a dream?\" The ghost smiled and said, \"Of course! Let\\'s pick a happy dream for you.\" Together, they picked a dream about playing in a big park with lots of friends.\\n\\nAmy said, \"Thank you, ghost!\" The ghost smiled and said, \"You\\'re welcome. Now, go back to sleep and enjoy your dream.\" Amy closed her eyes, feeling happy and safe with her new friend.\\n\\nAnd so, Amy had a wonderful dream, thanks to the kind ghost. From that night on, the ghost would always visit Amy and help her pick the best dreams, and they became the best of friends.<EOS>',\n",
       " '<SOS>Once upon a time, in a big forest, there was a tiny mushroom. It was all alone. The sun was very harsh, and the mushroom did not like it. It wanted to find a friend to play with and to help it hide from the sun.\\n\\nOne day, a little bunny came hopping by. The mushroom called out, \"Hello, bunny! Will you be my friend?\" The bunny looked at the mushroom and smiled. \"Sure, I will be your friend. Let\\'s play together!\" The bunny and the mushroom played all day, and they were very happy.\\n\\nAs they played, the bunny realized that the mushroom needed help to hide from the harsh sun. So, the bunny dug a hole in the ground and put the mushroom inside. Now, the mushroom was safe and cool. The mushroom and the bunny were the best of friends, and they played in the forest every day.<EOS>',\n",
       " '<SOS>Once upon a time, there was a queen. She was a very nice queen. She had a big, pretty castle. The queen had a lot of work to do every day. But today, she wanted to relax.\\n\\nThe queen went to the park to relax. She sat on a soft, green grass. The queen saw a bug. The bug was disgusting. The queen did not like the disgusting bug.\\n\\nThe queen went back to her castle. She was happy to be away from the disgusting bug. Now, the queen could relax in her big, pretty castle. The queen smiled and had a good day.<EOS>',\n",
       " '<SOS>Once upon a time, there was a little white cat named Fluffy. Fluffy loved to play with her best friend, a small boy named Timmy. They played outside in the sun every day. Fluffy liked to chase Timmy, and Timmy liked to run.\\n\\nOne day, Timmy learned a new word at school. He wanted to teach Fluffy the word too. Timmy said, \"Fluffy, the word is \\'repeat\\'. Can you say \\'repeat\\'?\" Fluffy looked at Timmy and said, \"Meow.\" Timmy laughed and said, \"No, Fluffy, say \\'repeat\\'.\"\\n\\nFluffy tried again and said, \"Meow-peat.\" Timmy clapped his hands and said, \"Good job, Fluffy! You said the word!\" Fluffy was very happy. She liked learning new words with Timmy. From that day on, Fluffy and Timmy played a game where they would teach each other new words. They had lots of fun together, and they lived happily ever after.<EOS>',\n",
       " '<SOS>Once upon a time, there was a big octopus. He lived in the deep blue sea. He had a friend, a reliable fish. They played together every day.\\n\\nOne day, the octopus and the fish found a big jug. They wanted to pour water on their friends for fun. But they couldn\\'t agree on who would pour the water. The octopus said, \"I want to pour the water!\" The fish said, \"No, I want to pour the water!\" They were not happy.\\n\\nThen, the octopus had an idea. He said, \"Let\\'s both pour the water!\" The fish liked the idea. They picked up the big jug together and poured water on all their friends. Everyone laughed and had fun. The octopus and the fish were happy again. They learned to share and play together. And they lived happily ever after.<EOS>',\n",
       " '<SOS>One day, a silly cat named Tom found a hoop in the yard. He wanted to play with it, but it was too big. Tom thought very hard about how to make the hoop smaller.\\n\\nTom had an idea. He would stretch the hoop to make it smaller. He put his paws on the hoop and pulled as hard as he could. The hoop started to stretch! It got smaller and smaller.\\n\\nNow, the hoop was just the right size for Tom to play with. He jumped through the hoop and chased it around the yard. Tom had so much fun playing with his new toy. And that is the story of the silly cat and the hoop.<EOS>',\n",
       " '<SOS>Once upon a time, there was a polite crab. The crab lived in the sea. The crab had many friends.\\n\\nOne day, the crab met a new friend. The new friend did not know how to play. The crab wanted to help the new friend.\\n\\nThe polite crab showed the new friend how to play. They played all day. They had lots of fun. The new friend was happy. The polite crab was happy too. They were best friends forever.<EOS>']"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f\"<SOS>{sentence}<EOS>\" for sentence in all_sentences[0:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = list(\n",
    "    data_generator(\n",
    "        sp_processor.encode_as_ids(\n",
    "            [f\"<SOS>{sentence}<EOS>\" for sentence in all_sentences[0:2000]]\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([51, 3, 3309, 28, 8, 10, 40, 61, 83, 26, 124, 10, 1969, 22, 15, 199],\n",
       "  [3, 3309, 28, 8, 10, 40, 61, 83, 26, 124, 10, 1969, 22, 15, 199, 5]),\n",
       " ([3, 3309, 28, 8, 10, 40, 61, 83, 26, 124, 10, 1969, 22, 15, 199, 5],\n",
       "  [3309, 28, 8, 10, 40, 61, 83, 26, 124, 10, 1969, 22, 15, 199, 5, 14]),\n",
       " ([3309, 28, 8, 10, 40, 61, 83, 26, 124, 10, 1969, 22, 15, 199, 5, 14],\n",
       "  [28, 8, 10, 40, 61, 83, 26, 124, 10, 1969, 22, 15, 199, 5, 14, 169]),\n",
       " ([28, 8, 10, 40, 61, 83, 26, 124, 10, 1969, 22, 15, 199, 5, 14, 169],\n",
       "  [8, 10, 40, 61, 83, 26, 124, 10, 1969, 22, 15, 199, 5, 14, 169, 12]),\n",
       " ([8, 10, 40, 61, 83, 26, 124, 10, 1969, 22, 15, 199, 5, 14, 169, 12],\n",
       "  [10, 40, 61, 83, 26, 124, 10, 1969, 22, 15, 199, 5, 14, 169, 12, 11])]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[0:5]  # This is what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 100, 20])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.view(input.size(0), -1, input.size(1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 4])\n",
      "torch.Size([1, 4, 4])\n",
      "tensor([[[ 0.3896, -1.1158, -0.0776,  0.2005],\n",
      "         [-0.5921, -0.7588,  1.7235, -0.2645],\n",
      "         [ 0.4052, -1.4948, -1.2203, -0.2848],\n",
      "         [-0.1106, -0.8791,  0.5177,  0.1964]]])\n",
      "tensor([[[ 0.3896, -0.5921,  0.4052, -0.1106],\n",
      "         [-1.1158, -0.7588, -1.4948, -0.8791],\n",
      "         [-0.0776,  1.7235, -1.2203,  0.5177],\n",
      "         [ 0.2005, -0.2645, -0.2848,  0.1964]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4, 4]),\n",
       " tensor([[[ 0.8913, -0.1910, -0.2951,  1.0082],\n",
       "          [-1.4955,  1.0798,  1.4008, -0.9566],\n",
       "          [ 0.9291, -1.5403, -1.3711, -1.0423],\n",
       "          [-0.3249,  0.6515,  0.2655,  0.9907]]], grad_fn=<PermuteBackward0>))"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With Learnable Parameters\n",
    "m = nn.BatchNorm1d(4, track_running_stats=True)\n",
    "# Without Learnable Parameters\n",
    "# m = nn.BatchNorm1d(3, affine=False)\n",
    "input = torch.randn(1, 4, 4)\n",
    "input_view = input.permute(0, 2, 1)\n",
    "print(input.shape)\n",
    "print(input_view.shape)\n",
    "print(input)\n",
    "print(input_view)\n",
    "output = m(input_view)\n",
    "output.shape, output.permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0199, -0.1250,  0.0559, -0.0535]) tensor([0.9924, 0.9283, 0.9085, 0.9216]) Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True) Parameter containing:\n",
      "tensor([0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1., 1., 1., 1.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(m.running_mean, m.running_var, m.weight, m.bias)\n",
    "for i in m.parameters():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "N_EMBED = 512\n",
    "N_HIDDEN = 512\n",
    "V = VOCAB_SIZE\n",
    "\n",
    "\n",
    "# C = nn.Embedding(V, N_EMBED)\n",
    "# The Query, Key and Value matrics for self attention\n",
    "class TinyStoriesTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TinyStoriesTransformer, self).__init__()\n",
    "        self.C = nn.Embedding(V, N_EMBED)\n",
    "        self.bn = nn.BatchNorm1d(N_EMBED, track_running_stats=True)\n",
    "        # TODO(Sid): Add positional encoding and 3 separate layers for a forward projection *before* passing to Wq, Wk and Wv\n",
    "        self.Wq = nn.Linear(N_EMBED, N_HIDDEN)\n",
    "        self.Wk = nn.Linear(N_EMBED, N_HIDDEN)\n",
    "        self.Wv = nn.Linear(N_EMBED, N_HIDDEN)\n",
    "\n",
    "        # Layer norm layer\n",
    "        self.ln_att = nn.LayerNorm(N_HIDDEN)\n",
    "        # Full MLP\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(N_HIDDEN, N_HIDDEN // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(N_HIDDEN // 2, N_HIDDEN),\n",
    "        )\n",
    "        self.bn_after_ff = nn.BatchNorm1d(N_HIDDEN, track_running_stats=True)\n",
    "        self.ln_ff = nn.LayerNorm(N_HIDDEN)\n",
    "\n",
    "        # Softmax layer\n",
    "        self.final_projection = nn.Linear(N_HIDDEN, V)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_embed = self.C(x)  # T * N_EMBED\n",
    "        x_embed_permuted = x_embed.permute(0, 2, 1)  # N_EMBED * T\n",
    "        x_embed_normed = self.bn(x_embed_permuted)\n",
    "        x_embed_normed = x_embed_normed.permute(0, 2, 1)  # T * N_EMBED\n",
    "        # Sublayer 1\n",
    "        q = self.Wq(x_embed_normed)  # T * N_HIDDEN\n",
    "        k = self.Wk(x_embed_normed)  # T * N_HIDDEN\n",
    "        v = self.Wv(x_embed_normed)  # T * N_HIDDEN\n",
    "\n",
    "        a = torch.bmm(q, k.transpose(-2, -1)) / (N_HIDDEN**0.5)\n",
    "        self.effective_T = a.shape[1]\n",
    "        mask = torch.tril(torch.ones(self.effective_T, self.effective_T))\n",
    "        mask = mask.masked_fill(\n",
    "            mask[: self.effective_T, : self.effective_T] == 0, float(\"-inf\")\n",
    "        )\n",
    "        self.a = a\n",
    "        a = a + mask\n",
    "        self.a_softmax = torch.functional.F.softmax(a, dim=-1)\n",
    "\n",
    "        weighted_attention = self.a_softmax @ v  # T * N_HIDDEN\n",
    "        attention_output = self.ln_att(\n",
    "            weighted_attention + x_embed_normed\n",
    "        )  # T * N_HIDDEN, Residual connection\n",
    "        # layer_norm_output = self.ln(attention_output)\n",
    "\n",
    "        # Sub layer 2\n",
    "        ff_output = self.ff(attention_output)  # T * N_HIDDEN\n",
    "        ff_output_permuted = ff_output.permute(0, 2, 1)\n",
    "        ff_output_normed = self.bn_after_ff(ff_output_permuted)\n",
    "        ff_output_normed = ff_output_normed.permute(0, 2, 1)\n",
    "        layer_norm_output_final = self.ln_ff(\n",
    "            attention_output + ff_output_normed\n",
    "        )  # T * N_HIDDEN, Residual connection\n",
    "        return self.final_projection(layer_norm_output_final)  # B * T * V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinyStoriesTransformer(\n",
       "  (C): Embedding(10000, 512)\n",
       "  (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (Wq): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (Wk): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (Wv): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (ln_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (ff): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
       "  )\n",
       "  (bn_after_ff): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (ln_ff): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (final_projection): Linear(in_features=512, out_features=10000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_story_model = TinyStoriesTransformer()\n",
    "tiny_story_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    tiny_story_model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    ")\n",
    "# for parameter_values in parameters:\n",
    "#     for parameter in parameter_values:\n",
    "#         print(\".\", end=\"\")\n",
    "#         parameter.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over fit a batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([i[0] for i in all_data])\n",
    "Y = torch.tensor([i[1] for i in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([372012, 16]), torch.Size([372012, 16]))"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample, y_sample = X[0:200, :], Y[0:200, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  53,   28,    8,   10,   40,   61,   83,   26,  124,   10, 1969,   22,\n",
      "           15,  199,    5,   14],\n",
      "        [  28,    8,   10,   40,   61,   83,   26,  124,   10, 1969,   22,   15,\n",
      "          199,    5,   14,  169],\n",
      "        [   8,   10,   40,   61,   83,   26,  124,   10, 1969,   22,   15,  199,\n",
      "            5,   14,  169,   12],\n",
      "        [  10,   40,   61,   83,   26,  124,   10, 1969,   22,   15,  199,    5,\n",
      "           14,  169,   12,   11],\n",
      "        [  40,   61,   83,   26,  124,   10, 1969,   22,   15,  199,    5,   14,\n",
      "          169,   12,   11, 1445],\n",
      "        [  61,   83,   26,  124,   10, 1969,   22,   15,  199,    5,   14,  169,\n",
      "           12,   11, 1445,    9],\n",
      "        [  83,   26,  124,   10, 1969,   22,   15,  199,    5,   14,  169,   12,\n",
      "           11, 1445,    9,   57],\n",
      "        [  26,  124,   10, 1969,   22,   15,  199,    5,   14,  169,   12,   11,\n",
      "         1445,    9,   57,   24],\n",
      "        [ 124,   10, 1969,   22,   15,  199,    5,   14,  169,   12,   11, 1445,\n",
      "            9,   57,   24,   12],\n",
      "        [  10, 1969,   22,   15,  199,    5,   14,  169,   12,   11, 1445,    9,\n",
      "           57,   24,   12,  211]])\n",
      "tensor([[  28,    8,   10,   40,   61,   83,   26,  124,   10, 1969,   22,   15,\n",
      "          199,    5,   14,  169],\n",
      "        [   8,   10,   40,   61,   83,   26,  124,   10, 1969,   22,   15,  199,\n",
      "            5,   14,  169,   12],\n",
      "        [  10,   40,   61,   83,   26,  124,   10, 1969,   22,   15,  199,    5,\n",
      "           14,  169,   12,   11],\n",
      "        [  40,   61,   83,   26,  124,   10, 1969,   22,   15,  199,    5,   14,\n",
      "          169,   12,   11, 1445],\n",
      "        [  61,   83,   26,  124,   10, 1969,   22,   15,  199,    5,   14,  169,\n",
      "           12,   11, 1445,    9],\n",
      "        [  83,   26,  124,   10, 1969,   22,   15,  199,    5,   14,  169,   12,\n",
      "           11, 1445,    9,   57],\n",
      "        [  26,  124,   10, 1969,   22,   15,  199,    5,   14,  169,   12,   11,\n",
      "         1445,    9,   57,   24],\n",
      "        [ 124,   10, 1969,   22,   15,  199,    5,   14,  169,   12,   11, 1445,\n",
      "            9,   57,   24,   12],\n",
      "        [  10, 1969,   22,   15,  199,    5,   14,  169,   12,   11, 1445,    9,\n",
      "           57,   24,   12,  211],\n",
      "        [1969,   22,   15,  199,    5,   14,  169,   12,   11, 1445,    9,   57,\n",
      "           24,   12,  211,   12]])\n"
     ]
    }
   ],
   "source": [
    "print(x_sample[0:10, :])\n",
    "print(y_sample[0:10, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 16])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_path, epoch, optimizer, loss):\n",
    "    torch.save(\n",
    "        {\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"loss\": loss,\n",
    "        },\n",
    "        model_path,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_model(model, model_path, optimizer):\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "    epoch = checkpoint[\"epoch\"]\n",
    "    loss = checkpoint[\"loss\"]\n",
    "    return model, optimizer, epoch, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                             \r"
     ]
    }
   ],
   "source": [
    "n_epochs = 200\n",
    "epochs_iter = iter(range(n_epochs))\n",
    "tiny_story_model.train()\n",
    "with tqdm(total=n_epochs, desc=\"Epochs\", leave=False) as progress_bar:\n",
    "    for epoch in epochs_iter:\n",
    "        optimizer.zero_grad()\n",
    "        z = tiny_story_model(x_sample)\n",
    "        act = torch.softmax(z, dim=-1)  # B* T * V, where V is the\n",
    "        # print(act.shape, y_sample.shape)\n",
    "\n",
    "        act = act.view(-1, V)\n",
    "        y_sample_view = y_sample.view(-1)\n",
    "\n",
    "        loss = ce_loss(act, y_sample_view)\n",
    "\n",
    "        train_loss_values.append(loss.item())\n",
    "        if epoch % 10 == 0:\n",
    "            # print(\".\", end=\"\")\n",
    "            progress_bar.set_description(\n",
    "                f\"Epoch [{epoch+1}/{n_epochs}], Loss: {np.round(loss.item(), decimals=4)}, Last 5 losses: {', '.join([str(np.round(i, decimals=4)) for i in train_loss_values[-5:]])}\"\n",
    "            )\n",
    "        if epoch + 1 % 100 == 0:\n",
    "            save_model(\n",
    "                tiny_story_model,\n",
    "                f\"model_overfitted_epoch_{(epoch+1)}_batch_{(epoch+1)}.pth\",\n",
    "                epoch,\n",
    "                optimizer,\n",
    "                loss,\n",
    "            )\n",
    "        # print(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Cross entropy between the output of the FF layer_norm_output_final and the target y\n",
    "    # print(act.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.plot(train_loss_values[600:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinyStoriesTransformer(\n",
       "  (C): Embedding(10000, 512)\n",
       "  (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (Wq): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (Wk): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (Wv): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (ln_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (ff): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
       "  )\n",
       "  (bn_after_ff): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (ln_ff): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (final_projection): Linear(in_features=512, out_features=10000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_model = TinyStoriesTransformer()\n",
    "dummy_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51, 3, 1900, 11, 10]\n",
      "torch.Size([1, 5])\n",
      "There was a  [little girl named Beep loved to go fast and said, \"Mom, \"Mom, \"Mom, \"Mom, \"Mom, \"Mom, \"Mom, \"Mom, \"Mom, \"Mom, \"Mom, \"Mom, \"Mom, ]\n"
     ]
    }
   ],
   "source": [
    "# grab a random token and make the network generate things\n",
    "# def generate_text(model, sp_processor, test_sentence):\n",
    "test_sentence = \"There was a \"\n",
    "tiny_story_model.eval()\n",
    "# token = torch.randint(0, V, (1, 1)).to(device)\n",
    "tokens = sp_processor.encode_as_ids(f\"<SOS>{test_sentence}\")\n",
    "print(tokens)\n",
    "generated_text = []\n",
    "\n",
    "tokens = torch.tensor([tokens]).to(device)\n",
    "prev_tokens = tokens\n",
    "print(tokens.shape)\n",
    "for i in range(50):\n",
    "    with torch.no_grad():\n",
    "        z = tiny_story_model(prev_tokens)\n",
    "        act = torch.softmax(z, dim=-1)\n",
    "        act = act.view(-1, V)  # len(generated_tokens) +i * V\n",
    "        token = torch.argmax(act, dim=-1)\n",
    "        # print(token.shape)\n",
    "        token = token[-1]\n",
    "        # print(token)\n",
    "        # print('.')\n",
    "        generated_text.append(int(token))\n",
    "        prev_tokens = torch.cat((prev_tokens, torch.tensor([[token]])), dim=1)\n",
    "print(test_sentence + \" [\" + sp_processor.decode_ids(generated_text) + \" ]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0000000e+00, 1.2472578e-01, 8.7527424e-01, ..., 3.5056533e-07,\n",
       "       1.4254650e-03, 6.5302983e-02], dtype=float32)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1549 3249\n",
      "[1.14454900e-28 3.63722359e-26 1.72720156e-05 1.42857149e-01\n",
      " 6.00345945e-01]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.subplot()\n",
    "vals = tiny_story_model.a_softmax.view(-1).detach().numpy()\n",
    "print(np.count_nonzero(vals), len(vals))\n",
    "non_zeros = vals[np.where(vals != 0)]\n",
    "print(np.quantile(non_zeros, [0.01, 0.05, 0.5, 0.95, 0.99]))\n",
    "_ = ax.hist(non_zeros, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5]) torch.Size([2, 3])\n",
      "tensor([[[ 0.9000,  5.8000,  0.2000, -0.6500,  0.3000],\n",
      "         [ 0.9000, -1.8000,  0.2000,  0.6500,  7.3000],\n",
      "         [10.9000, -1.8000,  0.2000, -0.6500,  0.3000]],\n",
      "\n",
      "        [[ 0.9000,  5.8000,  0.2000, -0.6500,  0.3000],\n",
      "         [ 0.9000, -1.8000,  0.2000,  0.6500,  7.3000],\n",
      "         [10.9000, -1.8000,  0.2000, -0.6500,  0.3000]]], requires_grad=True) tensor([[1, 4, 0],\n",
      "        [2, 1, 1]])\n",
      "torch.Size([6, 5]) torch.Size([6])\n",
      "tensor([[ 0.9000,  5.8000,  0.2000, -0.6500,  0.3000],\n",
      "        [ 0.9000, -1.8000,  0.2000,  0.6500,  7.3000],\n",
      "        [10.9000, -1.8000,  0.2000, -0.6500,  0.3000],\n",
      "        [ 0.9000,  5.8000,  0.2000, -0.6500,  0.3000],\n",
      "        [ 0.9000, -1.8000,  0.2000,  0.6500,  7.3000],\n",
      "        [10.9000, -1.8000,  0.2000, -0.6500,  0.3000]],\n",
      "       grad_fn=<ViewBackward0>) tensor([1, 4, 0, 2, 1, 1])\n",
      ".\n",
      "tensor(4.5735, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Example of target with class indices\n",
    "random_loss = nn.CrossEntropyLoss()\n",
    "input = torch.tensor(\n",
    "    [\n",
    "        [\n",
    "            [0.9, 5.8, 0.2, -0.65, 0.3],\n",
    "            [0.9, -1.8, 0.2, 0.65, 7.3],\n",
    "            [10.9, -1.8, 0.2, -0.65, 0.3],\n",
    "        ],\n",
    "        [\n",
    "            [0.9, 5.8, 0.2, -0.65, 0.3],\n",
    "            [0.9, -1.8, 0.2, 0.65, 7.3],\n",
    "            [10.9, -1.8, 0.2, -0.65, 0.3],\n",
    "        ],\n",
    "    ],\n",
    "    requires_grad=True,\n",
    ")\n",
    "target = torch.tensor([[1, 4, 0], [2, 1, 1]], dtype=torch.long)\n",
    "print(input.shape, target.shape)\n",
    "print(input, target)\n",
    "input_view = input.view(-1, 5)\n",
    "target_view = target.view(-1)\n",
    "print(input_view.shape, target_view.shape)\n",
    "print(input_view, target_view)\n",
    "print(\".\")\n",
    "output = random_loss(input_view, target_view)\n",
    "print(output)\n",
    "# output.backward()\n",
    "# # Example of target with class probabilities\n",
    "# input = torch.randn(3, 5, requires_grad=True)\n",
    "# target = torch.randn(3, 5).softmax(dim=1)\n",
    "# output = loss(input, target)\n",
    "# output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
